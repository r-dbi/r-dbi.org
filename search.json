[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DBI for R",
    "section": "",
    "text": "R’s interface to databases, with a testable and human-readable specification, a selection of backend packages to connect with various databases, and a boilerplate for developing new backends.\n \n  \n   \n  \n    \n     GitHub"
  },
  {
    "objectID": "index.html#packages",
    "href": "index.html#packages",
    "title": "DBI for R",
    "section": "Packages",
    "text": "Packages\n\n\nInterface\nThe DBI package defines generic methods that work almost identically across databases. This is checked by DBItest, which also provides a human-readable specification.\n\n\nBackends\nThe RSQLite, RMariaDB, and RPostgres packages implement methods defined by DBI that connect to specific databases. There are more packages that connect to other databases.\n\n\nBoilerplate\nThe RKazam package makes it easy for package developers to create a new package to a new DBMS."
  },
  {
    "objectID": "index.html#blog-posts",
    "href": "index.html#blog-posts",
    "title": "DBI for R",
    "section": "Blog posts",
    "text": "Blog posts\n\n\n\n\n\nUsing Arrow for data transport\n\n\n\n\n\nWhat would DBI look like if implemented today?\n\n\n\n\n\nApr 14, 2024\n\n\nKirill Müller\n\n\n\n\n\n\n\nTowards sustainable DBI maintenance\n\n\n\n\n\nMeasuring our responsiveness to bug reports and feature requests, calling for contributions\n\n\n\n\n\nApr 7, 2024\n\n\nKirill Müller\n\n\n\n\n\n\n\nRecent improvements\n\n\n\n\n\nSummarizing the progress of 2022 and 2023\n\n\n\n\n\nApr 2, 2024\n\n\nKirill Müller\n\n\n\n\n\n\n\nMaintaining DBI, 4/4\n\n\n\n\n\nSummarizing the progress of 2021\n\n\n\n\n\nDec 21, 2021\n\n\nKirill Müller\n\n\n\n\n\n\n\nMaintaining DBI, 3/4\n\n\n\n\n\nSummarizing the progress of 2020\n\n\n\n\n\nJan 20, 2021\n\n\nKirill Müller\n\n\n\n\n\n\n\nMaintaining DBI, 2/4\n\n\n\n\n\nSummarizing the progress of 2019\n\n\n\n\n\nDec 19, 2019\n\n\nKirill Müller\n\n\n\n\n\n\n\nMaintaining DBI, 1/4\n\n\n\n\n\nSummarizing the progress of 2018\n\n\n\n\n\nDec 31, 2018\n\n\nKirill Müller\n\n\n\n\n\n\n\nDone “Establishing DBI”!?\n\n\n\n\n\nSummary of the “Establishing DBI” project\n\n\n\n\n\nMay 1, 2018\n\n\nKirill Müller\n\n\n\n\n\n\n\nConnecting to open source databases\n\n\n\n\n\nPresentation at rstudio::conf, San Diego\n\n\n\n\n\nFeb 2, 2018\n\n\nKirill Müller\n\n\n\n\n\n\n\nDBItest: Specification\n\n\n\n\n\nSummary of the “Improving DBI” project\n\n\n\n\n\nMay 15, 2017\n\n\nKirill Müller\n\n\n\n\n\n\n\nHalfway through “Improving DBI”\n\n\n\n\n\nIntermediate status report on the “Improving DBI” project\n\n\n\n\n\nDec 6, 2016\n\n\nKirill Müller\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "R-DBI blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nUsing Arrow for data transport\n\n\n\n\n\nWhat would DBI look like if implemented today?\n\n\n\n\n\n14 April 2024\n\n\nKirill Müller\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nTowards sustainable DBI maintenance\n\n\n\n\n\nMeasuring our responsiveness to bug reports and feature requests, calling for contributions\n\n\n\n\n\n07 April 2024\n\n\nKirill Müller\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nRecent improvements\n\n\n\n\n\nSummarizing the progress of 2022 and 2023\n\n\n\n\n\n02 April 2024\n\n\nKirill Müller\n\n\n14 min\n\n\n\n\n\n\n\n\n\n\n\n\nMaintaining DBI, 4/4\n\n\n\n\n\nSummarizing the progress of 2021\n\n\n\n\n\n21 December 2021\n\n\nKirill Müller\n\n\n11 min\n\n\n\n\n\n\n\n\n\n\n\n\nMaintaining DBI, 3/4\n\n\n\n\n\nSummarizing the progress of 2020\n\n\n\n\n\n20 January 2021\n\n\nKirill Müller\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nMaintaining DBI, 2/4\n\n\n\n\n\nSummarizing the progress of 2019\n\n\n\n\n\n19 December 2019\n\n\nKirill Müller\n\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n\nMaintaining DBI, 1/4\n\n\n\n\n\nSummarizing the progress of 2018\n\n\n\n\n\n31 December 2018\n\n\nKirill Müller\n\n\n11 min\n\n\n\n\n\n\n\n\n\n\n\n\nDone “Establishing DBI”!?\n\n\n\n\n\nSummary of the “Establishing DBI” project\n\n\n\n\n\n01 May 2018\n\n\nKirill Müller\n\n\n15 min\n\n\n\n\n\n\n\n\n\n\n\n\nConnecting to open source databases\n\n\n\n\n\nPresentation at rstudio::conf, San Diego\n\n\n\n\n\n02 February 2018\n\n\nKirill Müller\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nDBItest: Specification\n\n\n\n\n\nSummary of the “Improving DBI” project\n\n\n\n\n\n15 May 2017\n\n\nKirill Müller\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nHalfway through “Improving DBI”\n\n\n\n\n\nIntermediate status report on the “Improving DBI” project\n\n\n\n\n\n06 December 2016\n\n\nKirill Müller\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/dbi-3-4/index.html",
    "href": "blog/dbi-3-4/index.html",
    "title": "Maintaining DBI, 4/4",
    "section": "",
    "text": "The {DBI} package (database interface) provides an abstraction for communication between R and database management systems (DBMSes) by specifying a common application programming interface (API). Actual connectivity to DBMSes is established via database specific backend packages, implementing this interface. Examples for such backends include RPostgres, RMariaDB, and RSQLite. For users that are new to DBI, the introductory tutorial provides a good entry point for getting acquainted with some key concepts.\nThis blog post summarizes recent developments in {DBI} and related packages and concludes with an outlook on potential future directions. Similar articles are available from previous years, reporting on earlier states of the {DBI} ecosystem:\n\n3/4: January 2021\n2/4: December 2019\n1/4: December 2018"
  },
  {
    "objectID": "blog/dbi-3-4/index.html#what-is-dbi",
    "href": "blog/dbi-3-4/index.html#what-is-dbi",
    "title": "Maintaining DBI, 4/4",
    "section": "",
    "text": "The {DBI} package (database interface) provides an abstraction for communication between R and database management systems (DBMSes) by specifying a common application programming interface (API). Actual connectivity to DBMSes is established via database specific backend packages, implementing this interface. Examples for such backends include RPostgres, RMariaDB, and RSQLite. For users that are new to DBI, the introductory tutorial provides a good entry point for getting acquainted with some key concepts.\nThis blog post summarizes recent developments in {DBI} and related packages and concludes with an outlook on potential future directions. Similar articles are available from previous years, reporting on earlier states of the {DBI} ecosystem:\n\n3/4: January 2021\n2/4: December 2019\n1/4: December 2018"
  },
  {
    "objectID": "blog/dbi-3-4/index.html#recent-developments",
    "href": "blog/dbi-3-4/index.html#recent-developments",
    "title": "Maintaining DBI, 4/4",
    "section": "Recent developments",
    "text": "Recent developments\nSeveral packages associated with DBI have been updated since early 2021:\n\nDBI 1.1.1 -&gt; 1.1.2 (NEWS)\nRMariaDB 1.1.0 -&gt; 1.2.1 (NEWS)\nRPostgres 1.3.1 -&gt; 1.4.3 (NEWS)\nRSQLite 2.2.2 -&gt; 2.2.9 (NEWS)\nDBItest 1.7.0 -&gt; 1.7.2 (NEWS)\n\nAnd the following sections elaborate on some of the noteworthy changes and improvements contained in these updates, both user-visible and internal.\n\nClickable method documentation\nThe DBI method reference on https://dbi.r-dbi.org/reference/ has been updated to include clickable links to known DBI backends. This makes documentation specific to certain backends more accessible, as optional function arguments used by some backend implementations are only documented by the respective packages.\n\n\nFull support for AWS Redshift\nRedshift support has been greatly improved by Adam Foryś as part of the RPostgres package and both databases now pass all applicable tests offered by DBItest. The BLOB data type is currently not supported by Redshift and consequently, related tests are skipped. For connecting to a Redshift cluster, the RPostgres package exports Redshift() (to be used over Postgres()).\n\n\nFaster table imports\nPrevious versions of {RMariaDB} and {RPostgres} relied dbBind() for writing tables, using a prepared INSERT INTO ... VALUES (...) statement with placeholders. Contrary to the expectation, this was very inefficient, because each row requires a communication roundtrip to the server. To improve the situation, {RMariaDB} now uses LOAD DATA LOCAL INFILE to load data from a temporary CSV file. Recent MySQL server versions disable this capability by default, and therefore it is also disabled by default in {RMariaDB}. If your server supports this, enable fast loading by passing load_data_local_infile = TRUE to dbConnect(). For {RPostgres}, dbAppendTable() has been updated to use the same optimization as dbWriteTable() when writing data.\n\n\nWindows compatibility\n{RMariaDB} can now use the caching_sha2_password plugin on Windows which was permanently disabled on previous versions. This is important for connecting to recent versions of MySQL which require this plugin.\n\n\nExtended data types for SQLite\nThanks to Eric Anderson, {RSQLite} now returns typed data for columns declared with DATE, TIME and TIMESTAMP data types. To enable this feature, extended_types = TRUE has to be passed in dbConnect().\n\n\nInterrupt handling\nThe check_interrupts = TRUE argument to dbConnect() in {RPostgres} now correctly cancels the query and returns to the user as soon as an interrupt is signalled (by pressing Ctrl+C or Escape in RStudio). Thanks to Mateusz Żółtak for tests and discussion.\n\n\nAutomation\n{RMariaDB} is tested against all combinations of major MariaDB and MySQL client/server releases, while {RPostgres} is tested against all versions of PostgreSQL ≥ 10 using GitHub Actions. This guarantees compatibility with a broader range of database instances for both backends and for future updates to the corresponding packages. All tests are run daily, thereby ensuring that upstream updates remain compatible with backend implementations. The database servers are installed on GitHub Actions using dedicated actions for installing MariaDB, MySQL and Postgres, maintained by Andrew Kane.\nThanks to the automated monitoring of SQLite3 releases, the vendored code can be updated continuously with minimal delay over upstream releases. {RSQLite} now uses SQLite3 3.37.0 and became available from CRAN only 10 days after the upstream release.\n\n\nSimpler upgrade path for DBItest\nBy making it possible for backends to specify the supported version of {DBItest}, using tweaks(dbitest_version = \"x.y.z\"), it is now simpler to update {DBItest} on CRAN. Newly added tests in {DBItest} are skipped if the declared version is too low. Skipped tests are reported in the test results and can be fixed independently of the {DBItest} releases.\n\n\nInlined Boost headers\nThe {BH} package is a C++ header-only package containing in excess of 10,000 individual files and installation has proven challenging for some systems, such as Amazon’s Elastic File System. By vendoring only the required files into {RSQLite}, {RMariaDB} and {RPostgres}, it is no longer necessary to install {BH} to use these packages, and therefore the total number of files required to build these packages is greatly reduced. Thanks to RStudio for supporting this change.\n\n\nReorganized structure of the R code\n{DBI} uses S4 classes and generic functions to specify the interface to be implemented by backends, using database specific subclasses. Class specific generic implementations are consequently declared with setMethod(), using the following convention:\nsetMethod(\"foo\", c(\"myclass\", \"character\"), function(x, char_arg, ...) {\n  ...\n})\nInstead of passing an anonymous function as definition argument to setMethod(), this has been changed to a semantic equivalent which is more explicit:\nfoo_myclass_character &lt;- function(x, char_arg, ...) {\n  ...\n}\n\nsetMethod(\"foo\", c(\"myclass\", \"character\"), foo_myclass_mycharacter)\nReasons for this transformation were to make the respective implementations more accessible, as function definitions now can be displayed more easily via mypkg:::foo_myclass_character, and to generally make the code-base easier to read and navigate. In similar spirit, each such generic implementation is now defined in its own file with file names constructed as foo_myclass_mycharacter.R. This makes it immediately clear, exactly which methods are implemented by a package, simply from the list of associated files. Code transformation was carried out in semi-automated fashion, with the help of a script that uses infrastructure from the “Pre-processing R code” project."
  },
  {
    "objectID": "blog/dbi-3-4/index.html#future-work",
    "href": "blog/dbi-3-4/index.html#future-work",
    "title": "Maintaining DBI, 4/4",
    "section": "Future work",
    "text": "Future work\nThe {DBI} package provides a low-level interface for database connectivity with a narrow scope. Data query and manipulation tasks that are not in-scope for {DBI} are currently left to auxiliary packages, including dbplyr, dm, dbx and rquery. {DBI} uses S4, one of several systems for object-oriented programming in R. While S4 offers several advantages over its predecessor S3, including increased strictness and multiple dispatch, it also is more rigid compared to S3.   Consequently, once the definition of a generic is published, it is difficult to make changes without breaking downstream dependencies.\nThe first release of {DBI} dates back roughly 20 years and since, the package has been widely adopted by others, both for accessing databases or providing backends to DBMSes. Its success, combined with the rigidity imposed by S4, has made it difficult to extend the interface beyond what is currently offered. When considering new additions, there is pressure to get it right in the first attempt, thereby holding back less essential improvements.\nThe DBI specification in the {DBItest} package aims to standardize the feature set of {DBI}-compliant backends, and to provide a test suite against which conformity of an implementation can be verified. Due to differences in design of individual DBMSes, not all features of the DBI specification and therefore not all tests provided by {DBItest} are supported by all backend packages. Using a newly introduced mechanism, backends can declare, by means of tweaks, which tests to run in what way. This addresses some of the problems associated with implementing a test suite that can be re-used for several backends. General-purpose clients however, can only make guesses as to the exact feature set supported by a given backend or connection. There currently is no formal way to declare certain capabilities as missing (or available).\nBased on these observations, for extending DBI, it may be worthwhile to address the following two issues:\n\nFormal declaration of capabilities.\nDecoupling the user from the backend interface.\n\nThe new dbi3 repository contains a collection of issues, some of which will be easier to address after these changes are in place.\n\nCapabilities\nA mechanism is introduced by which backends can declare explicitly which features of DBI a particular connection supports. Examples for existing functionality that varies over backends include:\n\nSupport for BLOBs (not available e.g. in Redshift).\nSupport for logical columns (not available e.g. in SQL Server or SQLite).\nSupport for named or nested transactions (not standardized).\nPlaceholder character to use in parameterized queries (different across databases).\n\nIn the future, backends may also indicate:\n\nWhether asynchronous queries are supported (important for web development).\nWhether the database supports SQL or a different query language (DBI currently assumes SQL).\n\nThe list of possible capabilities will be maintained by DBI and {DBItest} will rely solely on these capabilities, foregoing the current tweaking mechanism. Users can in turn query these capabilities and act accordingly.\n\n\nSeparate user interface\nAs an evolution of the current approach, where users of DBI will often directly call methods that are mostly implemented by backends themselves, introduction of a separate user-facing API may be worthwhile. Based on plain functions and essentially providing a facade, this user interface would be sufficient for the overwhelming majority of use cases. At the same time, such an approach should contribute to simpler code with less duplication in backend packages.\nThe new user interface performs tasks that are common to all database backends (e.g. validation of arguments), and calls methods provided by the backends, in some cases dependent on declared capabilities. Overall, this should lead to less code that needs to be reimplemented across backends. The decoupling of interfaces could help with iterative improvements, while guaranteeing stability for users. As an example, a dbi_write_table() function that optionally creates and writes data to a database table might encompass the following functionality:\n\nIf the backend supports transactions:\n\nCall dbi_is_transacting() to determine if the statement is occurring as part of a transaction.\nCall dbi_begin_transaction() if it is not already part a transaction.\nUse dbi_begin_transaction(name = \"...\") if the backend supports named transactions.\n\nCall dbi_remove_table() and/or dbi_create_table() if necessary.\nCall dbi_append_table().\nCall dbi_commit() on success or dbi_rollback() on failure whenever transactions are supported.\n\nFor appending rows to a table, dbi_append_table() might check if the backend supports streaming uploads or if SQL should be created for inserting rows. In the latter case, the SQL statement (or multiple statements for large tables) could be constructed using quoted literals obtained from dbi_quote_literal(). The backend could indicate the maximum supported length of a statement, so that splitting of large tables into multiple chunks can happen automatically.\nAs a final example, a backend supporting asynchronous operations might rely entirely on DBI for providing the corresponding blocking operations. The asynchronous procedure provided by the backend could automatically be wrapped by a DBI function that only returns upon completion.\nSuch a split API would allow for generics declared by {DBI} for interfacing with backends to remain frozen. To extend or alter the signature of a generic, a new generic can be added, using some form of versioning (e.g. with a numeric suffix, such as dbAppendTable1(), dbAppendTable2(), etc.). With such an architecture, arguments in generics could be declared explicitly, without relying on forwarding via ..., as is done currently. The user is presented with a stable API with only backward-compatible changes, {DBI} internally decides which versions of a method to call. When a new version of a generic is introduced, {DBI} documents and proposes an upgrade path for backend implementers. In the long run this would also allow for transitioning to another object-oriented system such as S3 or R7 without introducing user-facing breaking changes.\nThis approach also enables support of rich callbacks: each function in the facade can notify listeners on entry and before returning. For example, a call to dbi_connect() would notify interested parties that a new connection has been established, and a call to dbi_query() issues callbacks with the query and the result. Potential use cases include:\n\nLogging as in {dblog}.\nThe Connections pane in RStudio.\nMocking (with hooks) as in {dittodb}.\n\nA versioning scheme could also be implemented for callbacks, keeping existing callbacks frozen while allowing for addition of new features that alter callback signatures."
  },
  {
    "objectID": "blog/dbi-3-4/index.html#acknowledgments",
    "href": "blog/dbi-3-4/index.html#acknowledgments",
    "title": "Maintaining DBI, 4/4",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI’d like to thank Jeroen Ooms and Gábor Csárdi for providing crucial infrastructure to support this and many other projects in the R ecosystem.\nThanks to the numerous contributors to the packages in the “Maintaining DBI” project in 2021:\n\nDBI: @bwohl, @cboettig, @dcassol, @jawond, @mmccarthy404, @pnacht, @r2evans, @vituri, and @zoushucai;\nRSQLite: @ablack3, @billy34, @edwindj, @gaborcsardi, @ggrothendieck, @giocomai, @habilzare, @honghh2018, @Jeff-Gui, @kevinushey, @mgirlich, @plantton, @schuemie, @Shicheng-Guo, and @tschoonj;\nRPostgres: @aleaficionado, @armenic, @ateucher, @baderstine, @beralef, @carlganz, @ColinFay, @dcaud, @dpprdan, @f-ritter, @galachad, @GitHubGeniusOverlord, @gontcharovd, @gtm19, @hadley, @jakob-r, @jeroen, @jkylearmstrong, @JSchoenbachler, @matthewgson, @mgirlich, @mmuurr, @mskyttner, @phedinkus, @ppssphysics, @RakeshG1, @rickbpdq, @samiaab1990, @sawnaanwas, @tomasjanikds, @vspinu, @waynelapierre, @zmbc, and @zozlak;\nRMariaDB: @bakiunal, @dirkschumacher, @hadley, @jeroen, @Mosk915, @noamross, @paulmaunders, @retowyss, @rorynolan, @twentytitus, @verajosemanuel, @wiligl, @Woosah, and @zoushucai.\nDBItest: @adamsma, and @michaelquinn32;\n\nThanks also to Nicolas Bennett for reviewing and editing this blog post."
  },
  {
    "objectID": "blog/dbi-3-2/index.html",
    "href": "blog/dbi-3-2/index.html",
    "title": "Maintaining DBI, 2/4",
    "section": "",
    "text": "DBI stands for database interface, and DBI is a package for connecting to database management systems (DBMS). The goal of DBI is to provide a common interface for accessing a database, regardless of the specific underlying DBMS.\nDBI works with a variety of DBMS, such as Postgres, MariaDB, and SQLite, allowing users to focus on the specifics of their project instead of setting up the infrastructure for data import and export.\nThe DBI package is perfect for anyone looking to connect to a database, read/write entire tables, and/or execute SQL queries. DBI offers more control to the user than packages such as {dbplyr}.\nThe current version of DBI is 1.1.0. This blog post summarizes recent developments in DBI and related packages."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#what-is-dbi",
    "href": "blog/dbi-3-2/index.html#what-is-dbi",
    "title": "Maintaining DBI, 2/4",
    "section": "",
    "text": "DBI stands for database interface, and DBI is a package for connecting to database management systems (DBMS). The goal of DBI is to provide a common interface for accessing a database, regardless of the specific underlying DBMS.\nDBI works with a variety of DBMS, such as Postgres, MariaDB, and SQLite, allowing users to focus on the specifics of their project instead of setting up the infrastructure for data import and export.\nThe DBI package is perfect for anyone looking to connect to a database, read/write entire tables, and/or execute SQL queries. DBI offers more control to the user than packages such as {dbplyr}.\nThe current version of DBI is 1.1.0. This blog post summarizes recent developments in DBI and related packages."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#specification-of-immediate-argument-to-dbsendquery-and-friends",
    "href": "blog/dbi-3-2/index.html#specification-of-immediate-argument-to-dbsendquery-and-friends",
    "title": "Maintaining DBI, 2/4",
    "section": "Specification of immediate argument to dbSendQuery() and friends",
    "text": "Specification of immediate argument to dbSendQuery() and friends\nTom Nolan raised an issue on GitHub, requesting to specify details of the behavior of query execution. It became apparent that the DBI specification did not account for database drivers where the execution path is substantially different for queries with or without parameters. Recent version of DBI mandated the use of a prepared statement or query for everything.\nSimilar problems have been noted in MariaDB, Postgres and SQL Server (when accessed through {odbc}): some statements cannot be executed as prepared statements, or prepared statements are disabled. Over the course of several months, the details of the required extension of this API were fleshed out.\nThe dbSendQuery(), dbGetQuery(), dbSendStatement() and dbExecute() methods gain a new immediate argument. By setting this argument to TRUE, a direct query is created, allowing to execute queries that could not be run previously. Arguably, this is one of those obscure features that are not noted until they are missed.\nIt is up to the individual backends to add support for this argument. The default value should be made backward-compatible with the previous version of DBI 1.0.0. It has already been implemented in the {odbc} package. Plans to implement this feature in both {RMariaDB} and {RPostgres} are underway.\n\nExamples using immediate\nlibrary(DBI)\ncon &lt;- dbConnect(odbc::odbc(), dsn = \"SQLServerConnection\")\n\n# Create local temporary tables:\n# Did not work before, temporary table was removed immediately.\ndbExecute(con, \"CREATE TABLE #temp (a integer)\", immediate = TRUE)\ndbExecute(con, \"INSERT INTO #temp VALUES (1)\", immediate = TRUE)\n\n# Show execution plan:\n# Did not work before, execution plan was never shown\ndbExecute(con, \"SET SHOWPLAN_TEXT ON\", immediate = TRUE)\ndbGetQuery(con, \"SELECT * FROM #temp WHERE a &gt; 0\")\ndbExecute(con, \"SET SHOWPLAN_TEXT OFF\", immediate = TRUE)"
  },
  {
    "objectID": "blog/dbi-3-2/index.html#connector-objects",
    "href": "blog/dbi-3-2/index.html#connector-objects",
    "title": "Maintaining DBI, 2/4",
    "section": "Connector objects",
    "text": "Connector objects\nThe existing method in DBI has been to create the driver object and then call dbConnect() with the connection arguments. However there are times when a user may need to do the following:\n\nSeparate connection arguments from establishing a connection\nSerialize the connector to file in order to establish the same connection later\nMaintain multiple connectors in a list for testing different DBMS\n\nIn order to address these use cases, users now have the ability to create a “connector object” that combines the driver and connection arguments, allowing the user to call dbConnect() without additional arguments. This feature is implemented in {DBI}, and works out of the box for all DBI backends.\n\nExample\nlibrary(DBI)\n\n# Old way:\ndrv &lt;- RSQLite::SQLite()\ncon &lt;- dbConnect(drv, dbname = \":memory:\")\ndbDisconnect(con)\n\n# New connector object:\ncnr &lt;- new(\"DBIConnector\",\n  .drv = RSQLite::SQLite(),\n  .conn_args = list(dbname = \":memory:\")\n)\ncnr\n\n## &lt;DBIConnector&gt;&lt;SQLiteDriver&gt;\n## Arguments:\n## $dbname\n## [1] \":memory:\"\n\ncon &lt;- dbConnect(cnr)\ndbDisconnect(con)\nIn addition, arguments can be functions, a useful feature for passwords and other sensitive connection data."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#logging-with-the-dblog-package",
    "href": "blog/dbi-3-2/index.html#logging-with-the-dblog-package",
    "title": "Maintaining DBI, 2/4",
    "section": "Logging with the {dblog} package",
    "text": "Logging with the {dblog} package\nWhen using applications in production, keeping logs is an invaluable part of a sound infrastructure. The new {dblog} package is designed to be as simple as possible. It can be used as a standalone package or in conjunction with packages like {dbplyr}.\n{dblog} helps both with troubleshooting as well as auditing the queries that that are used to access a database. Similar to Perl’s DBI::log, the goal of {dblog} is to implement logging for arbitrary DBI backends.\n{dblog} is straightforward in its use. Start by initializing a logging driver using dblog() prior to connecting to a database management system. All calls to DBI methods are logged and by default printed to the console (or redirected to a file). The entirety of the logging output is runnable R code, so users can copy, paste, and execute the logging code for debugging.\n\nUsing dblog() to connect to SQLite\nlibrary(dblog)\n\ndrv &lt;- dblog(RSQLite::SQLite())\n#&gt; drv1 &lt;- RSQLite::SQLite()\n\n\nAll calls to DBI methods are logged, by default to the console\nconn &lt;- dbConnect(drv, file = \":memory:\")\n#&gt; conn1 &lt;- dbConnect(drv1, file = \":memory:\")\n\ndbWriteTable(conn, \"iris\", iris[1:3, ])\n#&gt; dbWriteTable(conn1, name = \"iris\", value = structure(list(Sepal.Length = c(5.1, 4.9, \n#&gt; 4.7), Sepal.Width = c(3.5, 3, 3.2), Petal.Length = c(1.4, 1.4, 1.3), Petal.Width = c(0.2, \n#&gt; 0.2, 0.2), Species = structure(c(1L, 1L, 1L), .Label = c(\"setosa\", \"versicolor\", \n#&gt; \"virginica\"), class = \"factor\")), row.names = c(NA, 3L), class = \"data.frame\"), overwrite = FALSE, \n#&gt;     append = FALSE)\n\ndata &lt;- dbGetQuery(conn, \"SELECT * FROM iris\")\n#&gt; dbGetQuery(conn1, \"SELECT * FROM iris\")\n#&gt; ##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; ## 1          5.1         3.5          1.4         0.2  setosa\n#&gt; ## 2          4.9         3.0          1.4         0.2  setosa\n#&gt; ## 3          4.7         3.2          1.3         0.2  setosa\n\ndbDisconnect(conn)\n#&gt; dbDisconnect(conn1)\n\ndata\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 2          4.9         3.0          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\nThis also works in scenarios where DBI is used under the hood by other packages like dbplyr or tidypredict. The log will represent the DBI operations issued, which allows for a better understanding of the internals."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#testing-your-infrastructure-for-dbi-compatibility",
    "href": "blog/dbi-3-2/index.html#testing-your-infrastructure-for-dbi-compatibility",
    "title": "Maintaining DBI, 2/4",
    "section": "Testing your infrastructure for DBI compatibility",
    "text": "Testing your infrastructure for DBI compatibility\nDBItest (on CRAN in version 1.7.0) is currently geared towards usage as part of a package’s test suite. With some effort it is possible to test a database backend against a custom database. This can help verify that your database installation gives expected results when accessed with DBI with specific connection arguments. The DBItest article contains a new section that describes how to achieve this, including a primer on using {dblog} to understand the cause of test failures."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#a-list-of-dbi-backends",
    "href": "blog/dbi-3-2/index.html#a-list-of-dbi-backends",
    "title": "Maintaining DBI, 2/4",
    "section": "A list of DBI backends",
    "text": "A list of DBI backends\nThe new backends repository lists all known DBI backends, as retrieved via a code search on GitHub. The list is available in the README, and as a static web API for programmatic processing."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#better-handling-of-time-zones",
    "href": "blog/dbi-3-2/index.html#better-handling-of-time-zones",
    "title": "Maintaining DBI, 2/4",
    "section": "Better handling of time zones",
    "text": "Better handling of time zones\nTime zones are used to convert between absolute time and civil time, where absolute time exists independent of human-created measures such as calendars, days, and dates, whereas civil time is comprised of years, months, days, hours, minutes, and seconds. For a more in-depth reading on absolute time, civil time, and time zones, please read this excerpt from the ODBC README.\nFor programming and data analysis, accurate handling time zones is crucial. {odbc} has set an example for how to handle time zones through the inclusion of timezone and timezone_out arguments to dbConnect(). The timezone argument controls the server time zone, which may be different from UTC. The timezone_out argument specifies the time zone to use for displaying times.\nThis strategy gives the user control over datetime information passed on to and retrieved from the database. Both arguments in combination should be able to support a broad variety of use cases and server setups. {RMariaDB} and {RPostgres} will incorporate this strategy with their next CRAN release. {RPostgres} already has gained a timezone argument in its dbConnect() method."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#window-function-support-in-rsqlite",
    "href": "blog/dbi-3-2/index.html#window-function-support-in-rsqlite",
    "title": "Maintaining DBI, 2/4",
    "section": "Window function support in {RSQLite}",
    "text": "Window function support in {RSQLite}\nRSQLite 2.1.4 and later includes sqlite &gt;= 3.29.0, which introduces support for window functions.\nlibrary(tidyverse)\nlibrary(dbplyr)\n\ntbl &lt;- memdb_frame(a = rep(1:2, 5), b = 1:10)\n\ntbl %&gt;% \n  group_by(a) %&gt;%\n  window_order(b) %&gt;% \n  mutate(c = cumsum(b)) %&gt;% \n  ungroup()\n\n## # Source:     lazy query [?? x 3]\n## # Database:   sqlite 3.30.1 [:memory:]\n## # Ordered by: b\n##        a     b     c\n##    &lt;int&gt; &lt;int&gt; &lt;int&gt;\n##  1     1     1     1\n##  2     1     3     4\n##  3     1     5     9\n##  4     1     7    16\n##  5     1     9    25\n##  6     2     2     2\n##  7     2     4     6\n##  8     2     6    12\n##  9     2     8    20\n## 10     2    10    30"
  },
  {
    "objectID": "blog/dbi-3-2/index.html#cii-best-practices-badges-for-all-repos",
    "href": "blog/dbi-3-2/index.html#cii-best-practices-badges-for-all-repos",
    "title": "Maintaining DBI, 2/4",
    "section": "CII “best practices” badges for all repos",
    "text": "CII “best practices” badges for all repos\nCII “best practices” have been implemented for {DBItest}, {RMariaDB}, {RPostgres} and {RSQLite}. The {DBItest} repository has a brand-new badge, the badges for the other repositories will follow suit."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#package-updates",
    "href": "blog/dbi-3-2/index.html#package-updates",
    "title": "Maintaining DBI, 2/4",
    "section": "Package updates",
    "text": "Package updates\nThe following package versions were sent to CRAN in conjunction with this blog post:\n\nDBI 1.1.0 (NEWS)\nDBItest 1.7.0 (NEWS)\nRMariaDB 1.0.8 (NEWS)\nRPostgres 1.2.0 (NEWS)\nRSQLite 2.1.5 (NEWS)\n\nBefore that, minor updates of the database backend packages were necessary to comply with stricter CRAN checks and toolchain updates."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#future-work",
    "href": "blog/dbi-3-2/index.html#future-work",
    "title": "Maintaining DBI, 2/4",
    "section": "Future work",
    "text": "Future work\nThe remainder of the blog post discusses future directions for DBI and the backend packages.\n\nDBI tutorials\nImproving documentation is a priority. DBI is still lacking an up-to-date tutorial with a low entry bar that helps users connect to their database and execute queries. The updated README is a little step forward, but a slightly more comprehensive versions with link to more detailed information would be helpful.\n\n\nTerraforming databases\nNow that using DBItest to test backends against custom infrastructure is understood, it becomes easier to enhance tests so that not only pristine setups are tested, but also databases with nonstandard settings for time zone, character encoding or collation. Terraform helps automating the setup of databases of different flavors on cloud providers such as Azure or Google Cloud. The desired state of computing infrastructure is specified in a declarative way. This allows testing a much broader variety of databases and configurations, without maintaining expensive infrastructure: databases can be spun up when needed and torn down when done.\nIt would be helpful to have a selection of open-source and commercial databases in different configuration settings ready for testing.\n\n\nQuery cancellation\nCurrently, {odbc} and many other backends freeze while a query is executed. It is easy to underestimate the runtime of a query, or to accidentally execute a query that is running too long. This severely hampers interactive workflows: a frozen R session means forcibly restarting R, or worse, the development environment.\nMateusz Żółtak has contributed a pull request that implements support for graceful query cancellation in {RPostgres}. Initial research suggests that for {odbc} it may be possible to implement this in a similar fashion. It remains to be seen if an implementation is viable, and if the database libraries used by {RMariaDB} and {RSQLite} support this mode of operation."
  },
  {
    "objectID": "blog/dbi-3-2/index.html#acknowledgments",
    "href": "blog/dbi-3-2/index.html#acknowledgments",
    "title": "Maintaining DBI, 2/4",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI’d like to thank Katharina Brunner and Jesse Mostipak for help with composing this blog post."
  },
  {
    "objectID": "blog/rstudio-conf/index.html",
    "href": "blog/rstudio-conf/index.html",
    "title": "Connecting to open source databases",
    "section": "",
    "text": "Connecting to open source databases - Posit"
  },
  {
    "objectID": "blog/rstudio-conf/index.html#link-to-video",
    "href": "blog/rstudio-conf/index.html#link-to-video",
    "title": "Connecting to open source databases",
    "section": "",
    "text": "Connecting to open source databases - Posit"
  },
  {
    "objectID": "blog/rstudio-conf/index.html#slides",
    "href": "blog/rstudio-conf/index.html#slides",
    "title": "Connecting to open source databases",
    "section": "Slides",
    "text": "Slides\n\n\n\nFull screen version"
  },
  {
    "objectID": "blog/dbi-1-final/index.html",
    "href": "blog/dbi-1-final/index.html",
    "title": "R-DBI",
    "section": "",
    "text": "The “Improving DBI” project, funded by the R consortium, started about a year ago. It includes\nBesides the established DBI and RSQLite packages, I have spent a lot of time on the new DBItest package. Final updates to these packages will be pushed to CRAN end of May this year, to give downstream maintainers some time to accommodate.\nThe follow-up project “Establishing DBI” will focus on fully DBI-compliant backends for MySQL/MariaDB and PostgreSQL, and on minor updates to the specs where appropriate."
  },
  {
    "objectID": "blog/dbi-1-final/index.html#dbitest-specification",
    "href": "blog/dbi-1-final/index.html#dbitest-specification",
    "title": "R-DBI",
    "section": "DBItest: Specification",
    "text": "DBItest: Specification\nA comprehensive backend-agnostic test suite for DBI backends is provided by the new DBItest package. When the project started, it was merely a collection of test cases. I have considerably expanded the test cases and provided a human-readable description for each, using literate programming techniques powered by roxygen2. The DBI package weaves these chunks of text to a single document that describes all test cases covered by the test suite, the textual DBI specification. This approach ensures that further updates to the specification are reflected in both the automatic tests and the text.\nThis package is aimed at backend implementers, who now can programmatically check with very little effort if their DBI backend conforms to the DBI specification. The verification can be integrated in the automated tests which are run as part of R’s package check mechanism in R CMD check. The odbc package, a new DBI-compliant interface to the ODBC interface, has been using DBItest from day one to enable test-driven development. The bigrquery package is another user of DBItest.\nBecause not all DBMS support all aspects of DBI, the DBItest package allows to restrict which parts of the specification are tested, or “tweak” certain aspects of the tests, e.g., the format of placeholders in parametrized queries. Adapting to other DBMS may require more work due to subtle differences in the implementation of SQL between various DBMS."
  },
  {
    "objectID": "blog/dbi-1-final/index.html#dbi-definition",
    "href": "blog/dbi-1-final/index.html#dbi-definition",
    "title": "R-DBI",
    "section": "DBI: Definition",
    "text": "DBI: Definition\nThis package has been around since 2001, it defines the actual DataBase Interface in R. I have taken over maintenance, and released versions 0.4-1, 0.5-1, and 0.6-1, with release of version 0.7 pending.\nThe most prominent change in this package is, of course, the textual DBI specification, which is included as an HTML vignette in the package. The documentation for the various methods defined by DBI is obtained directly from the specification. These help topics are combined in a sensible order to a single, self-contained document. This format is useful for both DBI users and implementers: users can look up the behavior of a method directly from its help page, and implementers can browse a comprehensive document that describes all aspects of the interface. I have also revised the description and the examples for all help topics.\nOther changes include:\n\nthe definition of new generics dbSendStatement() and dbExecute(), for backends that distinguish between queries that return a table and statements that manipulate data,\nthe new dbWithTransaction() generic and the dbBreak() helper function, thanks Barbara Borges Ribero,\nimproved or new default implementations for methods like dbGetQuery(), dbReadTable(), dbQuoteString(), dbQuoteIdentifier(),\ninternal changes that allow methods that don’t have a meaningful return value to return silently,\ntranslation of a helper function from C++ to R, to remove the dependency on Rcpp (thanks Hannes Mühleisen).\n\nFortunately, none of the changes seemed to have introduced any major regressions with downstream packages. The news contain a comprehensive list of changes."
  },
  {
    "objectID": "blog/dbi-1-final/index.html#rsqlite-implementation",
    "href": "blog/dbi-1-final/index.html#rsqlite-implementation",
    "title": "R-DBI",
    "section": "RSQLite: Implementation",
    "text": "RSQLite: Implementation\nRSQLite 1.1-2 is a complete rewrite of the original C implementation. Before focusing on compliance to the new DBI specification, it was important to assert compatibility to more than 100 packages on CRAN and Bioconductor that use RSQLite. These packages revealed many usage patterns that were difficult to foresee. Most of these usage patterns are supported in version 1.1-2, the more esoteric ones (such as supplying an integer where a logical is required) trigger a warning.\nSeveral rounds of “revdep checking” were necessary before most packages showed no difference in their check output compared to the original implementation. The downstream maintainers and the Bioconductor team were very supportive, and helped spotting functional and performance regressions during the release process. Two point releases were necessary to finally achieve a stable state.\nSupporting 64-bit integers also was trickier than anticipated. There is no built-in way to represent 64-bit integers in R. The bit64 package works around this limitation by using a numeric vector as storage, which also happens to use 8 bytes per element, and providing coercion functions. But when an integer column is fetched, it cannot be foreseen if a 64-bit value will occur in the result, and smaller integers must use R’s built-in integer type. For this purpose, an efficient data structure for collecting vectors, which is capable of changing the data type on the fly, has been implemented in C++. This data structure will be useful for many other DBI backends that need support for a 64-bit integer data type, and will be ported to the RKazam package in the follow-up project.\nOnce the DBI specification was completed, the process of making RSQLite compliant was easy: enable one of the disabled tests, fix the code, make sure all tests pass, rinse, and repeat. If you haven’t tried it, I seriosly recommend test-driven development, especially when the tests are already implemented.\nThe upcoming release of RSQLite 2.0 will require stronger adherence to the DBI specification also from callers. Where possible I tried to maintain backward compatibility, but in some cases breaks were inevitable because otherwise I’d have had to introduce far too many exceptions and corner cases in the DBI spec. For instance, row names are no longer included by default when writing or reading tables. The original behavior can be reenabled by calling pkgconfig::set_config(), so that packages or scripts that rely on row names continue to work as before. (The setting is active for the duration of the session, but only for the caller that has called pkgconfig::set_config().) I’m happy to include compatibility switches for other breaking changes if necessary and desired, to achieve both adherence to the specs and compatibility with existing behavior.\nA comprehensive list of changes can be found in the news."
  },
  {
    "objectID": "blog/dbi-1-final/index.html#other-bits-and-pieces",
    "href": "blog/dbi-1-final/index.html#other-bits-and-pieces",
    "title": "R-DBI",
    "section": "Other bits and pieces",
    "text": "Other bits and pieces\nThe RKazam package is a ready-to-use boilerplate for a DBI backend, named after the hypothetical DBMS used as example in a DBI vignette. It already “passes” all tests of the DBItest package, mostly by calling a function that skips the current test. Starting a DBI backend from scratch requires only copying and renaming the package’s code.\nR has limited support for time-of-day data. The hms package aims at filling this gap. It will be useful especially in the follow-up project, because SQLite doesn’t have an intrinsic type for time-of-day data, unlike many other DBMS."
  },
  {
    "objectID": "blog/dbi-1-final/index.html#next-steps",
    "href": "blog/dbi-1-final/index.html#next-steps",
    "title": "R-DBI",
    "section": "Next steps",
    "text": "Next steps\nThe ensemble CRAN release of the three packages DBI, DBItest and RSQLite will occur in parallel to the startup phase for the “Establishing DBI” follow-up project. This project consists of:\n\nFully DBI compatible backends for MySQL/MariaDB and Postgres\nA backend-agnostic C++ data structure to collect column data in the RKazam package\nSupport for spatial data\n\nIn addition, it will contain an update to the DBI specification, mostly concerning support for schemas and for querying the structure of the table returned for a query. Targeting three DBMS instead of one will help properly specify these two particularly tricky parts of DBI. I’m happy to take further feedback from users and backend implementers towards further improvement of the DBI specification."
  },
  {
    "objectID": "blog/dbi-1-final/index.html#acknowledgments",
    "href": "blog/dbi-1-final/index.html#acknowledgments",
    "title": "R-DBI",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nMany thanks to the R Consortium, who has sponsored this project, and to the many contributors who have spotted problems, suggested improvements, submitted pull requests, or otherwise helped make this project a great success. In particular, I’d like to thank Hadley Wickham, who suggested the idea, supported initial development of the DBItest package, and provided helpful feedback; and Christoph Hösler, Hannes Mühleisen, Imanuel Costigan, Jim Hester, Marcel Boldt, and @thrasibule for using it and contributing to it. I enjoyed working on this project, looking forward to “Establishing DBI”!"
  },
  {
    "objectID": "blog/dbi-4-3/index.html",
    "href": "blog/dbi-4-3/index.html",
    "title": "Using Arrow for data transport",
    "section": "",
    "text": "The third and final blog post explores the new Arrow Database Connectivity (ADBC) project, which provides a common interface for database access across ecosystems and database systems, using the Arrow data format as data exchange format. The associated R bindings available from the adbcdrivermanager package provide the foundation for the adbi package, bridging the gap between ADBC and DBI, and thereby enabling existing code that uses DBI to seamlessly interact with the new ADBC drivers.\nThis is a continuation of the first and second blog post in this series."
  },
  {
    "objectID": "blog/dbi-4-3/index.html#a-new-database-standard",
    "href": "blog/dbi-4-3/index.html#a-new-database-standard",
    "title": "Using Arrow for data transport",
    "section": "A new database standard?",
    "text": "A new database standard?\nThe DBI package offers consistent database access in R. Different database systems, such as PostgreSQL, MySQL, SQLite, and others, can be accessed through a common interface. To access a particular database, a driver package is required, such as RMariaDB, RPostgres, or RSQLite. These driver packages implement the DBI interface and bind to the database system’s native client library, such as Connector/C for MariaDB or libpq for PostgreSQL. A common interface is essential for users who want to switch between database systems or who want to use different database systems in the same project. Similar efforts exist in other ecosystems, such as Python’s DB-API 2.0. When considering the bigger picture, providing access to all databases for all ecosystems looks like this:\n\n\n\nDirect access to all databases from all ecosystems\n\n\nEach line represents a software package to develop and maintain, following changes in the database system and the target ecosystem. And, of course, the list of databases and ecosystems is not exhaustive. With every new system, many more connections need to be established. A daunting task!\nThis is where the ADBC project comes in. The Arrow Database Connectivity project aims to provide a common interface for database access across ecosystems, using the Arrow data format as data exchange format. This way, the above graphic can be simplified:\n\n\n\nAccess to all databases from all ecosystems through ADBC\n\n\nThis isn’t an entirely new idea. ODBC (Open Database Connectivity) and JDBC (Java Database Connectivity) have been around for a long time, with very similar goals. The new implementation can build on the lessons learned from these projects. The standardization around the Arrow data format is a significant advantage:\n\nMost data types typically supported by databases are supported directly, and the format is extensible.\nThe same data format can be used across ecosystems, avoiding conversions and copies.\nArrow is designed for high performance, with zero-copy data sharing between systems, with good support for both columnar and row-oriented data processing.\nWith FlightSQL, the same data format can be used for data exchange between client and server, avoiding serialization and deserialization.\nLike with ODBC, an ADBC driver is a shared library that can be loaded into any ecosystem. In addition, ADBC drivers can be tightly coupled with the target system, allowing to cover database-specific functionality that is not part of ADBC. An example is adbcpostgresql, which provides access to PostgreSQL-specific features: it exists as a standalone C library, as an R package (essentially vendoring the C library with some very lightweight boilerplate), as a Python package, and for many other target ecosystems. This greatly simplifies the installation and configuration of the driver.\n\nFor R, the main entry point is the adbcdrivermanager package. It provides the glue between R and the ADBC drivers. Because all ADBC drivers use the same Arrow data format, the adbcdrivermanager package can focus on the common functionality, such as connection management, query execution, and data retrieval. For example, the adbcpostgresql package imports the adbcdrivermanager package and provides the PostgreSQL-specific functionality, with currently very few additional features."
  },
  {
    "objectID": "blog/dbi-4-3/index.html#the-adbi-package",
    "href": "blog/dbi-4-3/index.html#the-adbi-package",
    "title": "Using Arrow for data transport",
    "section": "The adbi package",
    "text": "The adbi package\nBecause ADBC is a new project, it doesn’t yet cover all databases and ecosystems. To simplify the transition, the adbi package bridges ADBC drivers and DBI, enabling existing code that uses DBI to seamlessly interact with the new ADBC drivers. Thanks to Voltron Data for the collaboration on this project and for the support in developing the adbi package and the DBI extension.\nThe adbi package is available on CRAN and provides the following features:\n\nAccess to ADBC drivers through the DBI interface.\nData retrieval as data frames or Arrow, side by side, on the same connection object, using the new generics defined by DBI.\n\nThe DBI package provides a default implementation for the new Arrow generics, which is not optimized for performance but can be used to directly convert data provided by DBI backends to Arrow. However, by using adbi with the new DBI generics such as dbGetQueryArrow() or dbFetchArrow(), the data is never converted to a data frame, and the Arrow data format is used directly. See the relevant section in the first blog post for an example using PostgreSQL."
  },
  {
    "objectID": "blog/dbi-4-3/index.html#reimagining-dbi",
    "href": "blog/dbi-4-3/index.html#reimagining-dbi",
    "title": "Using Arrow for data transport",
    "section": "Reimagining DBI",
    "text": "Reimagining DBI\nThe dbi3 repository currently only hosts an issue tracker and a couple of scripts. Several issues were moved from other repositories in the r-dbi organization, with the intention of shaping the reimagining of a more modern database interface. With the new ADBC standard and the adbi package, it seemed worthwhile to revisit the responsibilities of a database interface in R.\nThe README now contains a categorization of the issues. It turns out that roughly a third of the issues can be addressed with ADBC and the adbcdrivermanager package, or a solution building on ADBC/adbcdrivermanager. Another thrid of the issues seem to belong in other packages such as dbplyr or dm. The the final third are issues that are not actionable at this time. The way forward therefore depends to a large extent on whether the ADBC project will be successful and whether the R community will adopt it. To help with this, DBI will keep and improve compatibility with ADBC and adbi.\nTo bring adbcdrivermanager on par with DBI, a few issues need to be addressed:\n\nSQL generation: how can dbplyr be connected to ADBC, either directly or via adbi?\nUsability: the adbcdrivermanager package looks more like an “implementer’s interface”, a convenience “user’s interface” wrapper or extension might make it easier to use. More on that below.\nTest suite: should a test package similarly to DBItest be created?\nInteroperability with existing DBI backends: can a generic ADBC driver be created so that any existing DBI backend can be used with ADBC? A prime candidate would be the odbc package, this would add support for all ODBC drivers to ADBC via R, until a native ADBC driver is available.\nDocumentation: the ADBC standard is well-documented, but the documentation specific to the R ecosystem could be expanded."
  },
  {
    "objectID": "blog/dbi-4-3/index.html#bindings-database-user-interface",
    "href": "blog/dbi-4-3/index.html#bindings-database-user-interface",
    "title": "Using Arrow for data transport",
    "section": "Bindings, database, user interface",
    "text": "Bindings, database, user interface\nLet’s step back a little to better understand the responsibilities of DBI and the various other components. What is core functionality, what can be provided by addon packages, and what use cases should be left for the end user to implement?\nAs an R user, I need to:\n\nconnect to a database,\nrun a query,\nread the resulting table,\ncreate a new table,\nwrite data to a table.\n\nI might also need to:\n\ncreate complex queries that involve multiple tables,\naccess metadata such as table and column names, column types, etc.,\nread data asynchronously.\n\nThe adbcdrivermanager package with the ADBC drivers tick almost all boxes from the “I need to” list, but none of the boxes from the “I might also need to” list. It does so by focusing on the following functionality:\n\nsimple connect and disconnect based on credentials,\ndata type mapping between Arrow and the native database driver,\ndata transfer in both directions,\nexecution of queries, with support for placeholders,\nreporting success or failure of queries and other operations.\n\nThis shows a good separation of concerns: the adbcdrivermanager package provides the core functionality (“bindings”), and other code can build on top of that to provide more advanced features (“user interface”).\nThe bindings alone are not enough to provide a good user experience. As an example, there are now several ways to access a PostgreSQL database from R:\n\nUse the RPostgres or RPostgreSQL packages, which provide a DBI backend for PostgreSQL.\nUse the adbcpostgresql package, which provides an ADBC driver for PostgreSQL.\nUse the adbi package, which provides a DBI backend for ADBC that allows accessing PostgreSQL through its ADBC driver.\nUse the odbc package, which provides a DBI backend for ODBC that allows accessing PostgreSQL through an ODBC driver.\n\nIn the past, “database driver” and “database” were often used interchangeably. Some of the operations required to effectively work with a database (such as listing the available tables) are currently tightly coupled with the database driver, but would be best handled by a separate component that dispatches by database. As long as the database driver reports on the kind of database, from which the SQL dialect could be inferred, other components can handle the remaining tasks. Specifically:\n\nTo write complex queries that involve multiple tables, dbplyr can dispatch on the SQL dialect and generate the appropriate SQL code.\nTo review and manage the tables in our database, the dm package has a concept of a standardized “meta-database”, similarly to INFORMATION_SCHEMA in SQL. (It is currently only used internally, but could be exposed.)\nTo efficiently access a database from a Shiny app, without blocking the user interface or other sessions handled by the same R process on the server, a helper that wraps ADBC’s low-level asynchronous support as promises would be most helpful.\nThe combination of bindings and database meta-information should be sufficient to satisfy virtually all other use cases across all databases. In cases where the bindings must provide a functionality that cannot be achieved through the query mechanism, ADBC makes it easy to extend the driver packages (such as the adbcpostgresql R package).\n\nIn contrast, in DBI, the three concepts “bindings”, “database”, and “user interface” are conflated. Disentangling them now will be hard."
  },
  {
    "objectID": "blog/dbi-4-3/index.html#conclusion",
    "href": "blog/dbi-4-3/index.html#conclusion",
    "title": "Using Arrow for data transport",
    "section": "Conclusion",
    "text": "Conclusion\nWith the implementation of adbi and the new DBI generics, the foundation for adopting ADBC has been laid. To future-proof ADBC and adbcdrivermanager, a good exercise might be to attempt implementing dbplyr for ADBC connection building directly on adbcdrivermanager, bypassing DBI. This will uncover missing pieces and clarify what kind of utilities is needed to make it a pleasant exercise to work with databases through ADBC in R. DBI will remain supported, but new development will be restricted to supporting the “I need to” list above.\nDoes the adbi package work for you? What would a good “user interface” package look like for ADBC? Use the adbi issue tracker to get in touch!\nThanks to Maëlle Salmon (@maelle) and Nicolas Bennett (@nbenn) for their help with the blog post, and to Voltron Data for supporting this effort."
  },
  {
    "objectID": "backends/index.html",
    "href": "backends/index.html",
    "title": "Backends for R-DBI",
    "section": "",
    "text": "Do you maintain a backend and think that yours should be on this list? Please open an issue in the backends repository."
  },
  {
    "objectID": "backends/index.html#adbi-0.1.1-2024-01-25",
    "href": "backends/index.html#adbi-0.1.1-2024-01-25",
    "title": "Backends for R-DBI",
    "section": "adbi 0.1.1 (2024-01-25) 🔗 🔗 🐛",
    "text": "adbi 0.1.1 (2024-01-25) 🔗 🔗 🐛\n‘DBI’ Compliant Database Access Using ‘ADBC’\nIn order to make Arrow Database Connectivity (‘ADBC’ https://arrow.apache.org/adbc/) accessible from R, an interface compliant with the ‘DBI’ package is provided, using driver back-ends that are implemented in the ‘adbcdrivermanager’ framework. This enables interacting with database systems using the Arrow data format, thereby offering an efficient alternative to ‘ODBC’ for analytical applications.\nMaintainer: Nicolas Bennett nicolas@cynkra.com. License: LGPL (&gt;= 2.1)"
  },
  {
    "objectID": "backends/index.html#azurekusto-1.1.3-2023-10-12",
    "href": "backends/index.html#azurekusto-1.1.3-2023-10-12",
    "title": "Backends for R-DBI",
    "section": "AzureKusto 1.1.3 (2023-10-12) 🔗 🐛",
    "text": "AzureKusto 1.1.3 (2023-10-12) 🔗 🐛\nInterface to ‘Kusto’/‘Azure Data Explorer’\nAn interface to ‘Azure Data Explorer’, also known as ‘Kusto’, a fast, distributed data exploration service from Microsoft: https://azure.microsoft.com/en-us/products/data-explorer/. Includes ‘DBI’ and ‘dplyr’ interfaces, with the latter modelled after the ‘dbplyr’ package, whereby queries are translated from R into the native ‘KQL’ query language and executed lazily. On the admin side, the package extends the object framework provided by ‘AzureRMR’ to support creation and deletion of databases, and management of database principals. Part of the ‘AzureR’ family of packages.\nMaintainer: Alex Kyllo jekyllo@microsoft.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#bigrquery-1.5.1-2024-03-14",
    "href": "backends/index.html#bigrquery-1.5.1-2024-03-14",
    "title": "Backends for R-DBI",
    "section": "bigrquery 1.5.1 (2024-03-14) 🔗 🐛",
    "text": "bigrquery 1.5.1 (2024-03-14) 🔗 🐛\nAn Interface to Google’s ‘BigQuery’ ‘API’\nEasily talk to Google’s ‘BigQuery’ database from R.\nMaintainer: Hadley Wickham hadley@posit.co. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#ckanr-0.7.0-2023-03-17",
    "href": "backends/index.html#ckanr-0.7.0-2023-03-17",
    "title": "Backends for R-DBI",
    "section": "ckanr 0.7.0 (2023-03-17) 🔗 🐛",
    "text": "ckanr 0.7.0 (2023-03-17) 🔗 🐛\nClient for the Comprehensive Knowledge Archive Network (‘CKAN’) API\nClient for ‘CKAN’ API (https://ckan.org/). Includes interface to ‘CKAN’ ‘APIs’ for search, list, show for packages, organizations, and resources. In addition, provides an interface to the ‘datastore’ API.\nMaintainer: Francisco Alves fjunior.alves.oliveira@gmail.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#clickhousehttp-0.3.3-2024-04-18",
    "href": "backends/index.html#clickhousehttp-0.3.3-2024-04-18",
    "title": "Backends for R-DBI",
    "section": "ClickHouseHTTP 0.3.3 (2024-04-18) 🐛",
    "text": "ClickHouseHTTP 0.3.3 (2024-04-18) 🐛\nA Simple HTTP Database Interface to ‘ClickHouse’\n‘ClickHouse’ (https://clickhouse.com/) is an open-source, high performance columnar OLAP (online analytical processing of queries) database management system for real-time analytics using SQL. This ‘DBI’ backend relies on the ‘ClickHouse’ HTTP interface and support HTTPS protocol.\nMaintainer: Patrice Godard patrice.godard@gmail.com. License: GPL-3"
  },
  {
    "objectID": "backends/index.html#connections-0.2.0-2023-12-18",
    "href": "backends/index.html#connections-0.2.0-2023-12-18",
    "title": "Backends for R-DBI",
    "section": "connections 0.2.0 (2023-12-18) 🔗 🐛",
    "text": "connections 0.2.0 (2023-12-18) 🔗 🐛\nIntegrates with the ‘RStudio’ Connections Pane and ‘pins’\nEnables ‘DBI’ compliant packages to integrate with the ‘RStudio’ connections pane, and the ‘pins’ package. It automates the display of schemata, tables, views, as well as the preview of the table’s top 1000 records.\nMaintainer: Edgar Ruiz edgar@posit.co. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#databaseconnector-6.3.2-2023-12-11",
    "href": "backends/index.html#databaseconnector-6.3.2-2023-12-11",
    "title": "Backends for R-DBI",
    "section": "DatabaseConnector 6.3.2 (2023-12-11) 🔗 🐛",
    "text": "DatabaseConnector 6.3.2 (2023-12-11) 🔗 🐛\nConnecting to Various Database Platforms\nAn R ‘DataBase Interface’ (‘DBI’) compatible interface to various database platforms (‘PostgreSQL’, ‘Oracle’, ‘Microsoft SQL Server’, ‘Amazon Redshift’, ‘Microsoft Parallel Database Warehouse’, ‘IBM Netezza’, ‘Apache Impala’, ‘Google BigQuery’, ‘Snowflake’, ‘Spark’, and ‘SQLite’). Also includes support for fetching data as ‘Andromeda’ objects. Uses either ‘Java Database Connectivity’ (‘JDBC’) or other ‘DBI’ drivers to connect to databases.\nMaintainer: Martijn Schuemie schuemie@ohdsi.org. License: Apache License"
  },
  {
    "objectID": "backends/index.html#dbi.rodbc-0.1-2",
    "href": "backends/index.html#dbi.rodbc-0.1-2",
    "title": "Backends for R-DBI",
    "section": "DBI.RODBC 0.1-2",
    "text": "DBI.RODBC 0.1-2\nDBI front-end to RODBC\nA simple DBI front-end to the RODBC package. This package uses version 4 style classes and methods to create a front-end to the existing RODBC (version 0.8-3) package.\nMaintainer: David A. James dj@bell-labs.com. License: GPL (version 2 or later)"
  },
  {
    "objectID": "backends/index.html#dbi.rpgsql-0.1-2",
    "href": "backends/index.html#dbi.rpgsql-0.1-2",
    "title": "Backends for R-DBI",
    "section": "DBI.RPgSQL 0.1-2",
    "text": "DBI.RPgSQL 0.1-2\nDBI front-end to RPgSQL\nA simple DBI front-end to the RPgSQL package. This package uses version 4 style classes and methods to create a front-end to the existing RPgSQL (version 1.0-0) package.\nMaintainer: David A. James dj@bell-labs.com. License: GPL (version 2 or later)"
  },
  {
    "objectID": "backends/index.html#dittodb-0.1.8-2024-04-09",
    "href": "backends/index.html#dittodb-0.1.8-2024-04-09",
    "title": "Backends for R-DBI",
    "section": "dittodb 0.1.8 (2024-04-09) 🔗 🐛",
    "text": "dittodb 0.1.8 (2024-04-09) 🔗 🐛\nA Test Environment for Database Requests\nTesting and documenting code that communicates with remote databases can be painful. Although the interaction with R is usually relatively simple (e.g. data(frames) passed to and from a database), because they rely on a separate service and the data there, testing them can be difficult to set up, unsustainable in a continuous integration environment, or impossible without replicating an entire production cluster. This package addresses that by allowing you to make recordings from your database interactions and then play them back while testing (or in other contexts) all without needing to spin up or have access to the database your code would typically connect to.\nMaintainer: Jonathan Keane jkeane@gmail.com. License: Apache License (&gt;= 2.0)"
  },
  {
    "objectID": "backends/index.html#duckdb-1.0.0-2-2024-07-19",
    "href": "backends/index.html#duckdb-1.0.0-2-2024-07-19",
    "title": "Backends for R-DBI",
    "section": "duckdb 1.0.0-2 (2024-07-19) 🔗 🐛",
    "text": "duckdb 1.0.0-2 (2024-07-19) 🔗 🐛\nDBI Package for the DuckDB Database Management System\nThe DuckDB project is an embedded analytical data management system with support for the Structured Query Language (SQL). This package includes all of DuckDB and a R Database Interface (DBI) connector.\nMaintainer: Kirill Müller kirill@cynkra.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#implyr-0.5.0-2024-02-06",
    "href": "backends/index.html#implyr-0.5.0-2024-02-06",
    "title": "Backends for R-DBI",
    "section": "implyr 0.5.0 (2024-02-06) 🐛",
    "text": "implyr 0.5.0 (2024-02-06) 🐛\nR Interface for Apache Impala\n‘SQL’ back-end to ‘dplyr’ for Apache Impala, the massively parallel processing query engine for Apache ‘Hadoop’. Impala enables low-latency ‘SQL’ queries on data stored in the ‘Hadoop’ Distributed File System ‘(HDFS)’, Apache ‘HBase’, Apache ‘Kudu’, Amazon Simple Storage Service ‘(S3)’, Microsoft Azure Data Lake Store ‘(ADLS)’, and Dell ‘EMC’ ‘Isilon’. See https://impala.apache.org for more information about Impala.\nMaintainer: Ian Cook ianmcook@gmail.com. License: Apache License 2.0 | file LICENSE"
  },
  {
    "objectID": "backends/index.html#lazysf-0.1.0-2020-11-14",
    "href": "backends/index.html#lazysf-0.1.0-2020-11-14",
    "title": "Backends for R-DBI",
    "section": "lazysf 0.1.0 (2020-11-14) 🐛",
    "text": "lazysf 0.1.0 (2020-11-14) 🐛\nDelayed Read for ‘GDAL’ Vector Data Sources\nLazy read for drawings. A ‘dplyr’ back end for data sources supported by ‘GDAL’ vector drivers, that allows working with local or remote sources as if they are in-memory data frames. Basic features works with any drawing format (‘GDAL vector data source’) supported by the ‘sf’ package.\nMaintainer: Michael Sumner mdsumner@gmail.com. License: GPL-3"
  },
  {
    "objectID": "backends/index.html#monetdb.r-2.0.0-2020-08-14",
    "href": "backends/index.html#monetdb.r-2.0.0-2020-08-14",
    "title": "Backends for R-DBI",
    "section": "MonetDB.R 2.0.0 (2020-08-14)",
    "text": "MonetDB.R 2.0.0 (2020-08-14)\nConnect MonetDB to R\nAllows to pull data from MonetDB into R.\nMaintainer: Mitchell Weggemans mitchell.weggemans@monetdbsolutions.com. License: MPL (== 2.0)"
  },
  {
    "objectID": "backends/index.html#monetdblite-0.6.0-2018-07-27",
    "href": "backends/index.html#monetdblite-0.6.0-2018-07-27",
    "title": "Backends for R-DBI",
    "section": "MonetDBLite 0.6.0 (2018-07-27) 🐛",
    "text": "MonetDBLite 0.6.0 (2018-07-27) 🐛\nIn-Process Version of ‘MonetDB’\nAn in-process version of ‘MonetDB’, a SQL database designed for analytical tasks. Similar to ‘SQLite’, the database runs entirely inside the ‘R’ shell.\nMaintainer: Hannes Mühleisen hannes@cwi.nl. License: MPL (== 2.0)"
  },
  {
    "objectID": "backends/index.html#noctua-2.6.2-2023-08-08",
    "href": "backends/index.html#noctua-2.6.2-2023-08-08",
    "title": "Backends for R-DBI",
    "section": "noctua 2.6.2 (2023-08-08) 🐛",
    "text": "noctua 2.6.2 (2023-08-08) 🐛\nConnect to ‘AWS Athena’ using R ‘AWS SDK’ ‘paws’ (‘DBI’ Interface)\nDesigned to be compatible with the ‘R’ package ‘DBI’ (Database Interface) when connecting to Amazon Web Service (‘AWS’) Athena https://aws.amazon.com/athena/. To do this the ‘R’ ‘AWS’ Software Development Kit (‘SDK’) ‘paws’ https://github.com/paws-r/paws is used as a driver.\nMaintainer: Dyfan Jones dyfan.r.jones@gmail.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#odbc-1.5.0-2024-06-05",
    "href": "backends/index.html#odbc-1.5.0-2024-06-05",
    "title": "Backends for R-DBI",
    "section": "odbc 1.5.0 (2024-06-05) 🔗 🔗 🐛",
    "text": "odbc 1.5.0 (2024-06-05) 🔗 🔗 🐛\nConnect to ODBC Compatible Databases (using the DBI Interface)\nA DBI-compatible interface to ODBC databases.\nMaintainer: Hadley Wickham hadley@posit.co. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#pool-1.0.3-2024-02-14",
    "href": "backends/index.html#pool-1.0.3-2024-02-14",
    "title": "Backends for R-DBI",
    "section": "pool 1.0.3 (2024-02-14) 🔗 🐛",
    "text": "pool 1.0.3 (2024-02-14) 🔗 🐛\nObject Pooling\nEnables the creation of object pools, which make it less computationally expensive to fetch a new object. Currently the only supported pooled objects are ‘DBI’ connections.\nMaintainer: Hadley Wickham hadley@posit.co. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rathena-2.6.1-2022-12-20",
    "href": "backends/index.html#rathena-2.6.1-2022-12-20",
    "title": "Backends for R-DBI",
    "section": "RAthena 2.6.1 (2022-12-20) 🐛",
    "text": "RAthena 2.6.1 (2022-12-20) 🐛\nConnect to ‘AWS Athena’ using ‘Boto3’ (‘DBI’ Interface)\nDesigned to be compatible with the R package ‘DBI’ (Database Interface) when connecting to Amazon Web Service (‘AWS’) Athena https://aws.amazon.com/athena/. To do this ‘Python’ ‘Boto3’ Software Development Kit (‘SDK’) https://boto3.amazonaws.com/v1/documentation/api/latest/index.html is used as a driver.\nMaintainer: Dyfan Jones dyfan.r.jones@gmail.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rclickhouse-0.6.9-2024-01-19",
    "href": "backends/index.html#rclickhouse-0.6.9-2024-01-19",
    "title": "Backends for R-DBI",
    "section": "RClickhouse 0.6.9 (2024-01-19) 🐛",
    "text": "RClickhouse 0.6.9 (2024-01-19) 🐛\n‘Yandex Clickhouse’ Interface for R with Basic ‘dplyr’ Support\n‘Yandex Clickhouse’ (https://clickhouse.com/) is a high-performance relational column-store database to enable big data exploration and ‘analytics’ scaling to petabytes of data. Methods are provided that enable working with ‘Yandex Clickhouse’ databases via ‘DBI’ methods and using ‘dplyr’/‘dbplyr’ idioms.\nMaintainer: Christian Hotz-Behofsits christian.hotz-behofsits@wu.ac.at. License: GPL-2"
  },
  {
    "objectID": "backends/index.html#rh2-0.2.4-2018-03-14",
    "href": "backends/index.html#rh2-0.2.4-2018-03-14",
    "title": "Backends for R-DBI",
    "section": "RH2 0.2.4 (2018-03-14)",
    "text": "RH2 0.2.4 (2018-03-14)\nDBI/RJDBC Interface to H2 Database\nDBI/RJDBC interface to h2 database. h2 version 1.3.175 is included.\nMaintainer: “David M. Kaplan” dmkaplan2000@gmail.com. License: Mozilla Public License 1.1"
  },
  {
    "objectID": "backends/index.html#rjdbc-0.2-10-2022-03-24",
    "href": "backends/index.html#rjdbc-0.2-10-2022-03-24",
    "title": "Backends for R-DBI",
    "section": "RJDBC 0.2-10 (2022-03-24)",
    "text": "RJDBC 0.2-10 (2022-03-24)\nProvides Access to Databases Through the JDBC Interface\nThe RJDBC package is an implementation of R’s DBI interface using JDBC as a back-end. This allows R to connect to any DBMS that has a JDBC driver.\nMaintainer: Simon Urbanek Simon.Urbanek@r-project.org. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rmariadb-1.3.2-2024-05-27",
    "href": "backends/index.html#rmariadb-1.3.2-2024-05-27",
    "title": "Backends for R-DBI",
    "section": "RMariaDB 1.3.2 (2024-05-27) 🔗 🔗 🐛",
    "text": "RMariaDB 1.3.2 (2024-05-27) 🔗 🔗 🐛\nDatabase Interface and MariaDB Driver\nImplements a DBI-compliant interface to MariaDB (https://mariadb.org/) and MySQL (https://www.mysql.com/) databases.\nMaintainer: Kirill Müller kirill@cynkra.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rmysql-0.10.27-2023-12-04",
    "href": "backends/index.html#rmysql-0.10.27-2023-12-04",
    "title": "Backends for R-DBI",
    "section": "RMySQL 0.10.27 (2023-12-04) 🐛",
    "text": "RMySQL 0.10.27 (2023-12-04) 🐛\nDatabase Interface and ‘MySQL’ Driver for R\nLegacy ‘DBI’ interface to ‘MySQL’ / ‘MariaDB’ based on old code ported from S-PLUS. A modern ‘MySQL’ client written in ‘C++’ is available from the ‘RMariaDB’ package.\nMaintainer: Jeroen Ooms jeroen@berkeley.edu. License: GPL-2"
  },
  {
    "objectID": "backends/index.html#rodbcdbi-0.1.1-2016-03-14",
    "href": "backends/index.html#rodbcdbi-0.1.1-2016-03-14",
    "title": "Backends for R-DBI",
    "section": "RODBCDBI 0.1.1 (2016-03-14)",
    "text": "RODBCDBI 0.1.1 (2016-03-14)\nProvides Access to Databases Through the ODBC Interface\nAn implementation of R’s DBI interface using ODBC package as a back-end. This allows R to connect to any DBMS that has a ODBC driver.\nMaintainer: Nagi Teramo teramonagi@gmail.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#roracle-1.3-1.1-2021-11-10",
    "href": "backends/index.html#roracle-1.3-1.1-2021-11-10",
    "title": "Backends for R-DBI",
    "section": "ROracle 1.3-1.1 (2021-11-10)",
    "text": "ROracle 1.3-1.1 (2021-11-10)\nOCI Based Oracle Database Interface for R\nOracle Database interface (DBI) driver for R. This is a DBI-compliant Oracle driver based on the OCI.\nMaintainer: Rajendra S. Pingte rajendra.pingte@oracle.com. License: LGPL"
  },
  {
    "objectID": "backends/index.html#rpostgres-1.4.7-2024-05-27",
    "href": "backends/index.html#rpostgres-1.4.7-2024-05-27",
    "title": "Backends for R-DBI",
    "section": "RPostgres 1.4.7 (2024-05-27) 🔗 🐛",
    "text": "RPostgres 1.4.7 (2024-05-27) 🔗 🐛\nC++ Interface to PostgreSQL\nFully DBI-compliant C++-backed interface to PostgreSQL https://www.postgresql.org/, an open-source relational database.\nMaintainer: Kirill Müller kirill@cynkra.com. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rpostgresql-0.7-6-2024-01-11",
    "href": "backends/index.html#rpostgresql-0.7-6-2024-01-11",
    "title": "Backends for R-DBI",
    "section": "RPostgreSQL 0.7-6 (2024-01-11) 🔗 🔗",
    "text": "RPostgreSQL 0.7-6 (2024-01-11) 🔗 🔗\nR Interface to the ‘PostgreSQL’ Database System\nDatabase interface and ‘PostgreSQL’ driver for ‘R’. This package provides a Database Interface ‘DBI’ compliant driver for ‘R’ to access ‘PostgreSQL’ database systems. In order to build and install this package from source, ‘PostgreSQL’ itself must be present your system to provide ‘PostgreSQL’ functionality via its libraries and header files. These files are provided as ‘postgresql-devel’ package under some Linux distributions. On ‘macOS’ and ‘Microsoft Windows’ system the attached ‘libpq’ library source will be used.\nMaintainer: Tomoaki Nishiyama tomoakin@staff.kanazawa-u.ac.jp. License: GPL-3 | file LICENSE"
  },
  {
    "objectID": "backends/index.html#rpresto-1.4.6-2023-11-01",
    "href": "backends/index.html#rpresto-1.4.6-2023-11-01",
    "title": "Backends for R-DBI",
    "section": "RPresto 1.4.6 (2023-11-01) 🐛",
    "text": "RPresto 1.4.6 (2023-11-01) 🐛\nDBI Connector to Presto\nImplements a ‘DBI’ compliant interface to Presto. Presto is an open source distributed SQL query engine for running interactive analytic queries against data sources of all sizes ranging from gigabytes to petabytes: https://prestodb.io/.\nMaintainer: Jarod G.R. Meng jarodm@fb.com. License: BSD_3_clause + file LICENSE"
  },
  {
    "objectID": "backends/index.html#rredshiftsql-0.1.2-2016-09-15",
    "href": "backends/index.html#rredshiftsql-0.1.2-2016-09-15",
    "title": "Backends for R-DBI",
    "section": "RRedshiftSQL 0.1.2 (2016-09-15)",
    "text": "RRedshiftSQL 0.1.2 (2016-09-15)\nR Interface to the ‘Redshift’ Database\nSuperclasses ‘PostgreSQL’ connection to help enable full ‘dplyr’ functionality on ‘Redshift’.\nMaintainer: Michael Treadwell michael.treadwell@interworks.com. License: GPL-2"
  },
  {
    "objectID": "backends/index.html#rsqlite-2.3.7-2024-05-27",
    "href": "backends/index.html#rsqlite-2.3.7-2024-05-27",
    "title": "Backends for R-DBI",
    "section": "RSQLite 2.3.7 (2024-05-27) 🔗 🐛",
    "text": "RSQLite 2.3.7 (2024-05-27) 🔗 🐛\nSQLite Interface for R\nEmbeds the SQLite database engine in R and provides an interface compliant with the DBI package. The source for the SQLite engine and for various extensions in a recent version is included. System libraries will never be consulted because this package relies on static linking for the plugins it includes; this also ensures a consistent experience across all installations.\nMaintainer: Kirill Müller kirill@cynkra.com. License: LGPL (&gt;= 2.1)"
  },
  {
    "objectID": "backends/index.html#rsqlserver-0.3.0-2017-06-17",
    "href": "backends/index.html#rsqlserver-0.3.0-2017-06-17",
    "title": "Backends for R-DBI",
    "section": "RSQLServer 0.3.0 (2017-06-17) 🐛",
    "text": "RSQLServer 0.3.0 (2017-06-17) 🐛\nSQL Server R Database Interface (DBI) and ‘dplyr’ SQL Backend\nUtilises The ‘jTDS’ project’s ‘JDBC’ 3.0 ‘SQL Server’ driver to extend ‘DBI’ classes and methods. The package also implements a ‘SQL’ backend to the ‘dplyr’ package.\nMaintainer: Imanuel Costigan i.costigan@me.com. License: GPL-2"
  },
  {
    "objectID": "backends/index.html#sergeant-0.9.1-2021-11-29",
    "href": "backends/index.html#sergeant-0.9.1-2021-11-29",
    "title": "Backends for R-DBI",
    "section": "sergeant 0.9.1 (2021-11-29) 🐛",
    "text": "sergeant 0.9.1 (2021-11-29) 🐛\nTools to Transform and Query Data with Apache Drill\nApache Drill is a low-latency distributed query engine designed to enable data exploration and analysis on both relational and non-relational data stores, scaling to petabytes of data. Methods are provided that enable working with Apache Drill instances via the REST API, DBI methods and using ‘dplyr’/‘dbplyr’ idioms. Helper functions are included to facilitate using official Drill Docker images/containers.\nMaintainer: Bob Rudis bob@rud.is. License: MIT + file LICENSE"
  },
  {
    "objectID": "backends/index.html#sparklyr-1.8.6-2024-04-29",
    "href": "backends/index.html#sparklyr-1.8.6-2024-04-29",
    "title": "Backends for R-DBI",
    "section": "sparklyr 1.8.6 (2024-04-29) 🐛",
    "text": "sparklyr 1.8.6 (2024-04-29) 🐛\nR Interface to Apache Spark\nR interface to Apache Spark, a fast and general engine for big data processing, see https://spark.apache.org/. This package supports connecting to local and remote Apache Spark clusters, provides a ‘dplyr’ compatible back-end, and provides an interface to Spark’s built-in machine learning algorithms.\nMaintainer: Edgar Ruiz edgar@rstudio.com. License: Apache License 2.0 | file LICENSE"
  },
  {
    "objectID": "blog/dbi-4-1/index.html",
    "href": "blog/dbi-4-1/index.html",
    "title": "Recent improvements",
    "section": "",
    "text": "The DBI package (database interface) is a layer between R and database management systems (DBMSes). Users who interact with DBMSes via the DBI package are able to use the same API for all DBMSes. Implementations of this API are provided by DBMS-specific backend packages, such as RPostgres, RMariaDB, and RSQLite. If you are new to DBI, you can find a good entry point in the introductory tutorial.\nThe interface is designed to be simple and consistent, making it easy to switch between different DBMSes. Packages built on top of DBI, such as dbplyr or arkdb, provide additional functionality and convenience. New backends can be implemented by following the DBI specification, which comes with a comprehensive test suite in the DBItest package. The RKazam template makes it easy to get started. (Spoiler alert: We know because a new backend has been added recently. Read on!)\nThis blog post series consists of three parts. In this first part, we summarize recent developments in DBI and related packages, including a glimpse on the new adbi package. The second part reviews the time it takes to respond to issues and pull requests. In the third part, we will do a deeper dive into the new adbi and adbcdrivermanager packages, which use the Arrow data exchange format and offer a more sustainable approach to database connectivity.\nSimilar articles are available from previous years, reporting on earlier states of the DBI ecosystem:\n\n4/4: December 2021\n3/4: January 2021\n2/4: December 2019\n1/4: December 2018"
  },
  {
    "objectID": "blog/dbi-4-1/index.html#what-is-dbi",
    "href": "blog/dbi-4-1/index.html#what-is-dbi",
    "title": "Recent improvements",
    "section": "",
    "text": "The DBI package (database interface) is a layer between R and database management systems (DBMSes). Users who interact with DBMSes via the DBI package are able to use the same API for all DBMSes. Implementations of this API are provided by DBMS-specific backend packages, such as RPostgres, RMariaDB, and RSQLite. If you are new to DBI, you can find a good entry point in the introductory tutorial.\nThe interface is designed to be simple and consistent, making it easy to switch between different DBMSes. Packages built on top of DBI, such as dbplyr or arkdb, provide additional functionality and convenience. New backends can be implemented by following the DBI specification, which comes with a comprehensive test suite in the DBItest package. The RKazam template makes it easy to get started. (Spoiler alert: We know because a new backend has been added recently. Read on!)\nThis blog post series consists of three parts. In this first part, we summarize recent developments in DBI and related packages, including a glimpse on the new adbi package. The second part reviews the time it takes to respond to issues and pull requests. In the third part, we will do a deeper dive into the new adbi and adbcdrivermanager packages, which use the Arrow data exchange format and offer a more sustainable approach to database connectivity.\nSimilar articles are available from previous years, reporting on earlier states of the DBI ecosystem:\n\n4/4: December 2021\n3/4: January 2021\n2/4: December 2019\n1/4: December 2018"
  },
  {
    "objectID": "blog/dbi-4-1/index.html#overall",
    "href": "blog/dbi-4-1/index.html#overall",
    "title": "Recent improvements",
    "section": "Overall",
    "text": "Overall\n\nImprove CI/CD infrastructure\nPackages run their own checks and the checks for related components. For example, DBI now runs DBItest with RSQLite, and DBItest runs checks for all backends, including odbc. This ensures interoperability between CRAN and development versions of the packages and helps to catch issues early.\nSeveral components simplify the day-to-day work:\n\nAviator helps ensuring always “green” builds on the main branch.\nIt is a “click-and-forget” solution that allows queueing a pull request so that it is automatically merged when all checks pass. I’m using this for all my packages now, and it has saved me a lot of time. I also tried the native GitHub merge queue, but it seems to require protecting the main branch, which is required for fledge. 👇\nfledge helps automating the release process.\nThis package generates a changelog from PR titles. In my setup, it is run daily and automatically updates NEWS.md. Before release to CRAN, the changelog is manually converted to release notes. Once a package is on CRAN, a GitHub release is created with these release notes.\nAll packages use a similar but not identical setup for CI/CD.\nFor example, the DBMS installed differs between backends. To manage this and also allow continuous improvement of the CI/CD process, I’m using bidirectional synchronization to and from a central repository. This allows me to make changes in one of the repositories and have them applied to all other repositories. Among other things, the improved CI/CD workflows automatically open pull requests for changes to autogenerated files such as .Rd files or the results of snapshot tests.\n\n\n\nImprove testing infrastructure\nTesting DBI and associated packages often requires a database server. While it is easy enough to install MariaDB and PostgreSQL to run locally, running Oracle and SQL Server on macOS requires Docker. If some databases require Docker, why not run all databases in Docker? This gives the additional advantage of being able to install different versions of the same database server side by side, and to easily recreate a fresh test environment.\nThe docker repository aims at providing a consistent and easy-to-use setup for all databases and all packages. It uses Docker Compose to turn otherwise complex command line invocations into a single docker-compose command. The goals are:\n\nHave a single robust command to create a server and a test connection, testable with CI/CD.\nOffer an easy way to run tests or scripts against a particular database server, using a development version of a backend package.\nSupport testing all useful combinations of DBI backend and database server.\nMake it easy to add new database versions, new databases, and new backends.\n\nThe repository is still in its early stages, but it already supports MariaDB, MySQL, PostgreSQL, SQLite, SQL Server, and Oracle. Feedback and contributions are welcome.\n\n\nDocumentation improvements\nVarious documentation improvements have been made:\n\nThe DBI specification is now version-controlled as Markdown files. This allows for more control and a simpler build process. Previously has been assembled at package build time from various sources.\nThe command execution and data retrieval flow has been clarified in the documentation. This has been a common source of confusion for new users.\nAll packages now use the new pkgdown documentation template at https://github.com/r-dbi/dbitemplate, and the website at https://r-dbi.org is now built using Quarto. Thanks to Maëlle Salmon (@maelle)!\n\n\n\nMove to cpp11\nThe RSQLite, RPostgres, and RMariaDB packages are now using the cpp11 package for the glue between R and C++. This header-only package provides a modern C++11 interface to R, the header files can be vendored into the backend packages if needed. Other highlights include the use “UTF-8 everywhere” paradigm, improved safety of C API calls, and a faster implementation of protection.\n\n\nAvoid tidying of duplicate column names\nThe RSQLite, RPostgres, and RMariaDB packages no longer change duplicate column names. The behavior in the presence of duplicate column names was not specified in the DBI specification, but imposing a tidying step seems out of scope for a database interface. It is now up to the user to handle duplicate column names, for example by using janitor::clean_names()."
  },
  {
    "objectID": "blog/dbi-4-1/index.html#adbi-new-release-in-collaboration-with-voltron-data",
    "href": "blog/dbi-4-1/index.html#adbi-new-release-in-collaboration-with-voltron-data",
    "title": "Recent improvements",
    "section": "adbi: new release in collaboration with Voltron Data",
    "text": "adbi: new release in collaboration with Voltron Data\nThe new adbi package bridges ADBC drivers and DBI. Examples include:\n\nadbcsqlite, on CRAN\nadbcpostgresql, on CRAN\nadbcsnowflake for Snowflake\nadbcflightsql for FlightSQL\nduckdb, which implements an ADBC driver in addition to the DBI backend\n\nADBC (Arrow database connectivity) is\n\nan API standard for database access libraries that uses Arrow for result sets and query parameters.\n\nThe adbi package allows existing code that uses DBI to seamlessly interact with the new ADBC drivers, but this will not improve performance. To facilitate the switch to using Arrow as a data interchange format, adbi supports access via data frames and Arrow side by side, on the same connection object, using the new generics defined by DBI. For example, with dbGetQueryArrow(), the result set is passed to R as an Arrow stream, bypassing the expensive conversion to data frames. More on that below.\nDevelopment of the adbi package has been made easy with the RKazam package, which is a template for creating DBI backends, and the DBItest package, which provides a battery of tests that all “pass” with the package generated from the template and help guide the development process. Thanks to Nicolas Bennett (@nbenn) for the implementation and the wonderful collaboration, and to Voltron Data for supporting this effort."
  },
  {
    "objectID": "blog/dbi-4-1/index.html#dbi",
    "href": "blog/dbi-4-1/index.html#dbi",
    "title": "Recent improvements",
    "section": "DBI",
    "text": "DBI\nThis package has seen a minor update to 1.2.2. See the change log for the full details.\n\nIntegration with Arrow\nDBI backens can now optionally support Arrow arrays and streams as the primary data exchange format. This is accessed through the new generics dbSendQueryArrow(), dbFetchArrow(), dbFetchArrowChunk(), dbGetQueryArrow(), dbReadTableArrow(), dbWriteTableArrow(), dbCreateTableArrow(), dbAppendTableArrow(), and dbBindArrow(). See the new vignette on Arrow support in DBI for details.\nA default implementation is provided in the DBI package, this means that the new interface can be used with any DBI backend without changes to the backend package. Performance and interoperability gains can be achieved by directly implementing the Arrow interface in the backend package, as the new adbi package does.\nThe following example illustrates two options to connect with a PostgreSQL database. In both scenarios, the libpq library is used to communicate with the database server. The RPostgres package links to libpq, the PostgreSQL client library, and uses this API directly to retrieve and ingest data from R via the DBI interface. The adbcpostgresql package also links to libpq but exposes ADBC, which is brought to R with the adbcdrivermanager package. On top of that, the adbi package interacts with arbitrary ADBC drivers (including adbcpostgresql) and exposes the functionality through DBI. The R user has the choice to access the data via data frames or via Arrow. When using adbi and the new dbGetQueryArrow(), the implementation will never convert the data to R data frames. This allows, e.g., directly saving the result to a Parquet file, or further processing it with Arrow. In all other cases, a conversion to R data frames will occur.\n\n\n\nData flow from libpq to consumers\n\n\nWhile the Arrow path seems to involve more components, it is the most efficient way to interact with the database because the data is threaded through from adbcpostgresql to R without any conversion or even copying. The only conversion occurs in adbcpostgresql, when the data returned by libpq is converted to Arrow format.\nWith FlightSQL, the data will be passed in the Arrow format end to end, this requires support in the database server. This is a promising development. By using adbi or adbcdrivermanager, R users can seamlessly transition to FlightSQL when it becomes available in their database.\nThanks to Voltron Data for supporting this effort!\n\n\nObject identifiers\nThe Id() class has been changed to unnamed components, as the explicit naming of the components (“database”, “schema”, “table”) was not used in practice. This also affects the dbQuoteIdentifier(), dbUnquoteIdentifier(), and dbListObjects() generics, which now accept and return unnamed Id() objects."
  },
  {
    "objectID": "blog/dbi-4-1/index.html#dbitest",
    "href": "blog/dbi-4-1/index.html#dbitest",
    "title": "Recent improvements",
    "section": "DBItest",
    "text": "DBItest\nThe DBItest package has seen a minor update to 1.8.1. See the change log for details.\n\nCode generation\nWhy good developers write bad unit tests? In a nutshell, production code should avoid repetition and hard-coded constant, while testing code should be as explicit and as easy to understand and execute as possible.\nThe DBItest package is home to both the specification of the DBI package and a test suite for DBI backends. As such, good software engineering practices are actually useful here and have helped cover many corner cases in the DBI backends. Running the tests in DBItest is easy, but in the case of a failure, the error messages are not always helpful. Backend developers typically have to read the test code to understand what went wrong. And if the actual test code hides between layers of abstraction, this can be a daunting task.\nCode generation has proved to be a powerful tool to peel off abstraction layers, for instance in the duckplyr project. In R, code is data, and the language and the associated packages are very well suited for this task. The long-term goal is to turn DBItest into a code generator rather than a test executor: the test code will be generated from a specification directly into the backend package and executed there. In the case of a failure, the error message will point to the generated code and to the relevant part of the specification. Failing tests can be executed trivially, very much like failures in regular tests. The expected behavior becomes apparent from the generated code, leading to a better understanding of the failure and a more efficient debugging process.\nA first step has been taken in this direction, the tests for the command execution and data retrieval flows via dbBind() have been refactored to generate inline code in the DBItest package. The process towards full code generation requires similar steps in a few other places to avoid hard-to-understand generated code, which would be even worse than the current situation.\n\n\nDecoupling from backends\nAs DBItest continues to evolve, and more backends are using it, the ability to add or update checks without affecting all downstream packages becomes crucial. Each new or modified test will require the backend package to opt in by updating the DBItest version in their tweaks() call. Once the code generation is in place, this will become less of an issue, but for now this helps with the ongoing development.\n\n\nOther improvements\nThe new Arrow generics are now tested in DBItest, and the tests have been integrated into the CI/CD pipeline.\nA new tweak allow_na_rows_affected has been added to support NA values returned from dbGetRowsAffected() and passed as the n argument to dbFetch()."
  },
  {
    "objectID": "blog/dbi-4-1/index.html#backend-packages-rsqlite-rmariadb-rpostgres",
    "href": "blog/dbi-4-1/index.html#backend-packages-rsqlite-rmariadb-rpostgres",
    "title": "Recent improvements",
    "section": "Backend packages: RSQLite, RMariaDB, RPostgres",
    "text": "Backend packages: RSQLite, RMariaDB, RPostgres\n\nRSQLite has seen a minor update, the current version is 2.3.6. See the change log for details.\nThe automatic update of the bundled SQLite library has enabled continuous and timely updates of the RSQLite package on CRAN. The latest version of SQLite is 3.45.2, and the RSQLite package is now bundling it. For this reason, the known authors of SQLite have been added to the DESCRIPTION file. This process allows quicker updates of SQLite than if installing from OS package repositories, and precise control of the underlying SQLite version used in a project.\nOther minor changes include support for the icpc compiler, and a new sqliteIsTransacting() function that returns if a transaction is active on the current connection.\nRMariaDB has also seen a minor update. The current version is 1.3.1. See the change log for details.\nMariaDB is a fork of MySQL, and both packages continue to evolve. There are small but important differences between the two DBMSs, and the RMariaDB package is now more explicit about the differences. Connections now inherit from \"MySQLConnection\" if a MySQL server is detected (server version &lt; 10.0 and server description does not contain \"MariaDB\"). The new mysql argument to dbConnect() allows overriding the autodetection. This means that code can behave differently depending on the underlying database server.\nSimilarly to RPostgres and odbc, RMariaDB now supports dbSendStatement(immediate = TRUE) and dbExecute(immediate = TRUE). This sends the query to the server without preparing it, which is mandatory for some queries. For this to work, the connection needs to be opened with the CLIENT_MULTI_STATEMENTS flag.\nOther changes include:\n\nSupport for TIME columns with subsecond precision.\nThe use of strings as default for JSON and all unknown column types.\n\nRPostgres has seen a minor update, mostly focusing on maintenance. The current version is 1.4.6. See the change log for details."
  },
  {
    "objectID": "blog/dbi-4-1/index.html#conclusion",
    "href": "blog/dbi-4-1/index.html#conclusion",
    "title": "Recent improvements",
    "section": "Conclusion",
    "text": "Conclusion\nQuite a few things have happened in the DBI ecosystem since the last blog post. Try out the new package versions, let us know if they work for you, and report any problems you encounter in the respective issue trackers on GitHub. Happy querying!"
  },
  {
    "objectID": "blog/dbi-4-1/index.html#acknowledgments",
    "href": "blog/dbi-4-1/index.html#acknowledgments",
    "title": "Recent improvements",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThanks to Maëlle Salmon (@maelle) and Nicolas Bennett (@nbenn) for their help with the blog post, and to the numerous contributors to the packages in the “Maintaining DBI” project in 2022 and 2023:\n\nDBI: @apalacio9502, @asadow, @bcorwin, @capitantyler, @chrisdane, @eauleaf, @eitsupi, @eriksquires, @fnavarro94, @GitHunter0, @hadley, @hannes101, @Jay123ub, @jd4ds, @kelseyroberts, @latot, @maelle, @matthiasgomolka, @mgirlich, @mmuurr, @nbenn, @philibe, @pnacht, @r2evans, @renkun-ken, @salim-b, @scottfrechette, and @tzakharko.\nDBItest: @barracuda156, @detule, @dpprdan, @hadley, @maelle, @MichaelChirico, @nbenn, @psychelzh, and @TSchiefer.\nRSQLite: @Antonov548, @arnaud-feldmann, @bpvgoncalves, @chodarq, @Daniel-Zhou-93, @DavorJ, @eriksquires, @gaospecial, @gavril0, @github-actions[bot], @hadley, @IdoBar, @JeremyPasco, @joethorley, @kjellpk, @kmishra9, @krlmlr, @lolow, @maelle, @MichaelChirico, @nathaneastwood, @nunotexbsd, @RoganGrant, @SarenT, @stephenashton-dhsc, @wibeasley, and @xmart.\nRPostgres: @abalter, @ablack3, @agilly, @aliarsalankazmi, @ankane, @Antonov548, @bhogan-mitre, @castagninojose, @DavisVaughan, @dmkaplan2000, @dpprdan, @geneorama, @gui-salome, @ilarischeinin, @jeroen, @karawoo, @kevinpalm, @kmishra9, @maelle, @majazaloznik, @meztez, @mgirlich, @mmuurr, @nbenn, @pachadotdev, @pedrobtz, @samterfa, @sbamin, @stefan-m-lenz, and @veer0318.\nRMariaDB: @Antonov548, @arecibo, @bergernetch, @BillWeld, @cboettig, @d-hansen, @EllyJung, @frabau1, @ghost, @GitHunter0, @GraphZal, @GundryLab, @hpages, @jay-sf, @jd4ds, @jeroen, @KevinYie, @kwakuduahc1, @lbui30, @LeeMendelowitz, @LukeBla, @maelle, @mbarneytu, @mgirlich, @MySocialPulse, @NoProblemJack, @pekkarr, @psychelzh, @pythiantech, @renkun-ken, @rorynolan, @ryan-hdez, @SwissMontainsBear, @uhkeller, and @vanhry."
  },
  {
    "objectID": "blog/dbi-2-final/index.html",
    "href": "blog/dbi-2-final/index.html",
    "title": "Done “Establishing DBI”!?",
    "section": "",
    "text": "The “Establishing DBI” project, funded by the R consortium, started about a year ago. It includes the completion of two new backends, RPostgres and RMariaDB, and a quite a few interface extensions and specifications. Learn more about DBI, R’s database interface, on https://r-dbi.org.\nThis blog post showcases only the visible changes, a substantial amount of work went into extending the DBI specification and making the three open-source database backends compliant to it. After describing the release of the two new backends RMariaDB and RPostgres, I’ll be discussing the following improvements:\nI conclude with an outlook on things left to do."
  },
  {
    "objectID": "blog/dbi-2-final/index.html#release-of-rpostgres-and-rmariadb",
    "href": "blog/dbi-2-final/index.html#release-of-rpostgres-and-rmariadb",
    "title": "Done “Establishing DBI”!?",
    "section": "Release of RPostgres and RMariaDB",
    "text": "Release of RPostgres and RMariaDB\nThe DBI specification has been formulated in the preceding R consortium project, “Improving DBI”. It is both an automated test suite and a human-readable description of behavior, implemented in the DBItest package. For this project, I extended this specification and could also use it to implement RPostgres and RMariaDB: for once, test-driven development was pure pleasure, because the tests were already there!\nI took over maintenance of the RPostgres and RMariaDB packages, which are complete rewrites of the RPostgreSQL and RMySQL packages, respectively. These packages use C++ (with Rcpp) as glue between R and the native database libraries. A reimplementation and release under a different name has made it much easier to fully conform to the DBI specification: only listing temporary tables and casting to blob or character is not supported by RMariaDB (due to a limitation of the DBMS), all other parts of the specification are fully covered.\nProjects that use RPostgreSQL or RMySQL can continue to do so, or switch to the new backends at their own pace (which likely requires some changes to the code). For new projects I recommend RPostgres or RMariaDB to take advantage of the thorougly tested codebases and of the consistency across backends."
  },
  {
    "objectID": "blog/dbi-2-final/index.html#schema-support",
    "href": "blog/dbi-2-final/index.html#schema-support",
    "title": "Done “Establishing DBI”!?",
    "section": "Schema support",
    "text": "Schema support\nConsistent access of tables in database schemas was planned for the “Improving DBI” project already, but I have implemented it only recently. It felt safer to see how the interface works on three backends, as opposed to implementing it for just RSQLite and then perhaps having to adapt it.\nThe new Id() function constructs identifiers. All arguments must be named, yet DBI doesn’t specify the argument names, because DBMS have an inconsistent notion of namespaces. The objects returned by Id() are “dumb”, they gain meaning only when used in methods such as dbQuoteIdentifier() or dbWriteTable().\nFor listing database objects in schemas, the new dbListObjects() generic can be used. It returns a data frame that contains identifiers (like those created by the Id() function) and a flag that indicates if the identifier is complete (i.e., pointing to a table or view) or a prefix. Incomplete identifiers can be passed to dbListObjects() again, which allows traversing the tree of database objects.\nThe following example assumes a schema my_schema. A table named my_table is created in this schema, objects are listed, and the table is read again.\nlibrary(RPostgres)\npg_conn &lt;- dbConnect(Postgres())\n\ntable_name &lt;- Id(schema = \"my_schema\", table = \"my_table\")\ntable_name\n\n## &lt;Id&gt; schema = my_schema, table = my_table\n\ndata &lt;- data.frame(a = 1:3, b = letters[1:3])\ndbWriteTable(pg_conn, table_name, data)\n\ndbListObjects(pg_conn)\n\n##                               table is_prefix\n## 1    &lt;Id&gt; table = geography_columns     FALSE\n## 2     &lt;Id&gt; table = geometry_columns     FALSE\n## 3      &lt;Id&gt; table = spatial_ref_sys     FALSE\n## 4       &lt;Id&gt; table = raster_columns     FALSE\n## 5     &lt;Id&gt; table = raster_overviews     FALSE\n## 6             &lt;Id&gt; table = topology     FALSE\n## 7                &lt;Id&gt; table = layer     FALSE\n## 8                 &lt;Id&gt; table = temp     FALSE\n## 9            &lt;Id&gt; schema = topology      TRUE\n## 10          &lt;Id&gt; schema = my_schema      TRUE\n## 11 &lt;Id&gt; schema = information_schema      TRUE\n## 12         &lt;Id&gt; schema = pg_catalog      TRUE\n## 13             &lt;Id&gt; schema = public      TRUE\n\ndbListObjects(\n  pg_conn,\n  prefix = Id(schema = \"my_schema\")\n)\n\n##                                       table is_prefix\n## 1 &lt;Id&gt; schema = my_schema, table = my_table     FALSE\n\ndbReadTable(pg_conn, table_name)\n\n##   a b\n## 1 1 a\n## 2 2 b\n## 3 3 c\nIn addition to dbReadTable() and dbWriteTable(), also dbExistsTable() and dbRemoveTable() and the new dbCreateTable() and dbAppendTable() (see below) support an Id() object as table name. The dbQuoteIdentifier() method converts these objects to SQL strings. Some operations (e.g. checking if a table exists) require the inverse, the new dbUnquoteIdentifier() generic takes care of converting valid SQL identifiers to (a list of) Id() objects:\nquoted &lt;- dbQuoteIdentifier(pg_conn, table_name)\nquoted\n\n## &lt;SQL&gt; \"my_schema\".\"my_table\"\n\ndbUnquoteIdentifier(pg_conn, quoted)\n\n## [[1]]\n## &lt;Id&gt; schema = my_schema, table = my_table\nThe new methods work consistently across backends, only RSQLite is currently restricted to the default schema. (Schemas in RSQLite are created by attaching another database, this use case seemed rather exotic but can be supported with the new infrastructure.)"
  },
  {
    "objectID": "blog/dbi-2-final/index.html#quoting-literal-values",
    "href": "blog/dbi-2-final/index.html#quoting-literal-values",
    "title": "Done “Establishing DBI”!?",
    "section": "Quoting literal values",
    "text": "Quoting literal values\nWhen working on the database backends, it has become apparent that quoting strings and identifiers isn’t quite enough. Now there is a way to quote arbitrary values, i.e. convert them to a string that can be pasted into an SQL query:\nlibrary(RSQLite)\nsqlite_conn &lt;- dbConnect(SQLite())\n\nlibrary(RMariaDB)\nmariadb_conn &lt;- dbConnect(MariaDB(), dbname = \"test\")\n\ndbQuoteLiteral(sqlite_conn, 1.5)\n\n## &lt;SQL&gt; 1.5\n\ndbQuoteLiteral(mariadb_conn, 1.5)\n\n## &lt;SQL&gt; 1.5\n\ndbQuoteLiteral(pg_conn, 1.5)\n\n## &lt;SQL&gt; 1.5::float8\n\ndbQuoteLiteral(mariadb_conn, Sys.time())\n\n## &lt;SQL&gt; '20180501204025'\n\ndbQuoteLiteral(pg_conn, Sys.time())\n\n## &lt;SQL&gt; '2018-05-01 22:40:25'::timestamp\nThe default implementation works for ANSI SQL compliant DBMS, the method for RPostgres takes advantage of the :: casting operator as seen in the examples."
  },
  {
    "objectID": "blog/dbi-2-final/index.html#more-fine-grained-creation-of-tables",
    "href": "blog/dbi-2-final/index.html#more-fine-grained-creation-of-tables",
    "title": "Done “Establishing DBI”!?",
    "section": "More fine-grained creation of tables",
    "text": "More fine-grained creation of tables\nDBI supports storing data frames as tables in the database via dbWriteTable(). This operation consists of multiple steps:\n\nChecking if a table of this name exists, if yes:\n\nIf overwrite = TRUE, removing the table\nIf not, throwing an error\n\nCreating the table with the correct field structure\nPreparing the data for writing\nWriting the data\n\nTo reduce complexity and allow for more options without cluttering the argument list of dbWriteTable(), DBI now provides generics for the individual steps:\n\nThe existing dbRemoveTable() generic has been extended with temporary and fail_if_missing arguments. Setting temporary = TRUE makes sure that only temporaries are removed. By default, trying to remove a table that doesn’t exist fails, setting fail_if_missing = FALSE changes this behavior to a silent success.\nThe new dbCreateTable() generic accepts a data frame or a character vector of DBMS data types and creates a table in the database. It builds upon the existing sqlCreateTable() generic and also supports the temporary argument. If a table by that name already exists, an error is raised.\nThe new dbAppendTable() generic uses a prepared statement (created via sqlAppendTableTemplate()) to efficiently insert rows into the database. This avoids the internal overhead of converting values to SQL literals.\n\nThe following example shows the creation and population of a table with the new methods.\ntable_name\n\n## &lt;Id&gt; schema = my_schema, table = my_table\n\ndbRemoveTable(pg_conn, table_name, fail_if_missing = FALSE)\n\ndbCreateTable(pg_conn, table_name, c(a = \"int8\", b = \"float8\"))\n\ndbAppendTable(pg_conn, table_name, data.frame(a = 1:3, b = 1:3))\n\n## [1] 3\n\nstr(dbReadTable(pg_conn, table_name))\n\n## 'data.frame':    3 obs. of  2 variables:\n##  $ a:integer64 1 2 3 \n##  $ b: num  1 2 3\nThe dbWriteTable() methods in the three backends have been adapted to use the new methods."
  },
  {
    "objectID": "blog/dbi-2-final/index.html#support-for-64-bit-integers",
    "href": "blog/dbi-2-final/index.html#support-for-64-bit-integers",
    "title": "Done “Establishing DBI”!?",
    "section": "Support for 64-bit integers",
    "text": "Support for 64-bit integers\nAs seen in the previous example, 64-bit integers can be read from the database. The three backends RSQLite, RPostgres and RMariaDB now also support writing 64-bit integers via the bit64 package:\ndata &lt;- data.frame(a = bit64::as.integer64(4:6), b = 4:6)\ndbAppendTable(pg_conn, table_name, data)\n\n## [1] 3\n\nstr(dbReadTable(pg_conn, table_name))\n\n## 'data.frame':    6 obs. of  2 variables:\n##  $ a:integer64 1 2 3 4 5 6 \n##  $ b: num  1 2 3 4 5 6\nBecause R still lacks support for native 64-bit integers, the bit64 package feels like the best compromise: the returned values can be computed on, or coerced to integer, numeric or even character depending on the application. In some cases, it may be useful to always coerce. This is where the new bigint argument to dbConnect() helps:\npg_conn_int &lt;- dbConnect(Postgres(), bigint = \"integer\")\nstr(dbReadTable(pg_conn_int, table_name))\n\n## 'data.frame':    6 obs. of  2 variables:\n##  $ a: int  1 2 3 4 5 6\n##  $ b: num  1 2 3 4 5 6\n\npg_conn_num &lt;- dbConnect(Postgres(), bigint = \"numeric\")\nstr(dbReadTable(pg_conn_num, table_name))\n\n## 'data.frame':    6 obs. of  2 variables:\n##  $ a: num  1 2 3 4 5 6\n##  $ b: num  1 2 3 4 5 6\n\npg_conn_chr &lt;- dbConnect(Postgres(), bigint = \"character\")\nstr(dbReadTable(pg_conn_chr, table_name))\n\n## 'data.frame':    6 obs. of  2 variables:\n##  $ a: chr  \"1\" \"2\" \"3\" \"4\" ...\n##  $ b: num  1 2 3 4 5 6\nThe bigint argument works consistently across the three backends RSQLite, RPostgres and RMariaDB, the DBI specification contains a test for and a description of the requirements."
  },
  {
    "objectID": "blog/dbi-2-final/index.html#geometry-columns",
    "href": "blog/dbi-2-final/index.html#geometry-columns",
    "title": "Done “Establishing DBI”!?",
    "section": "Geometry columns",
    "text": "Geometry columns\nPostgreSQL has support for user-defined data types, this is used e.g. by PostGIS to store spatial data. Before, user-defined data types were returned as character values, with a warning. Thanks to a contribution by Etienne B. Racine:\n\nthe warnings are gone,\nthe user-defined data type is now stored in an attribute of the column in the data frame,\ndetails on columns with user-defined data types are available in dbColumnInfo().\n\n\ndbCreateTable(\n  pg_conn,\n  \"geom_test\",\n  c(id = \"int4\", geom = \"geometry(Point, 4326)\")\n)\n\ndata &lt;- data.frame(\n  id = 1,\n  geom = \"SRID=4326;POINT(-71.060316 48.432044)\",\n  stringsAsFactors = FALSE\n)\ndbAppendTable(pg_conn, \"geom_test\", data)\n\n## [1] 1\n\nstr(dbReadTable(pg_conn, \"geom_test\"))\n\n## 'data.frame':    1 obs. of  2 variables:\n##  $ id  : int 1\n##  $ geom:Class 'pq_geometry'  chr \"0101000020E61000003CDBA337DCC351C06D37C1374D374840\"\n\nres &lt;- dbSendQuery(pg_conn, \"SELECT * FROM geom_test\")\ndbColumnInfo(res)\n\n##   name      type   .oid .known .typname\n## 1   id   integer     23   TRUE     int4\n## 2 geom character 101529  FALSE geometry\n\ndbClearResult(res)\nSpecial support for geometry columns is currently available only in RPostgres."
  },
  {
    "objectID": "blog/dbi-2-final/index.html#duplicate-column-names",
    "href": "blog/dbi-2-final/index.html#duplicate-column-names",
    "title": "Done “Establishing DBI”!?",
    "section": "Duplicate column names",
    "text": "Duplicate column names\nThe specification has been extended to disallow duplicate, empty or NA column names. The deduplication used by our three backends is similar to that used by tibble::set_tidy_names(), but the DBI specification does not require any particular deduplication mechanism. Syntactic names aren’t required either:\ndbGetQuery(sqlite_conn, \"SELECT 1, 2, 3\")\n\n##   1 2 3\n## 1 1 2 3\n\ndbGetQuery(sqlite_conn, \"SELECT 1 AS a, 2 AS a, 3 AS `a..2`\")\n\n##   a a..2 a..3\n## 1 1    2    3\n\ndbGetQuery(mariadb_conn, \"SELECT 1, 2, 3\")\n\n##   1 2 3\n## 1 1 2 3\n\ndbGetQuery(mariadb_conn, \"SELECT 1 AS a, 2 AS a, 3 AS `a..2`\")\n\n##   a a..2 a..3\n## 1 1    2    3\n\ndbGetQuery(pg_conn, \"SELECT 1, 2, 3\")\n\n##   ?column? ?column?..2 ?column?..3\n## 1        1           2           3\n\ndbGetQuery(pg_conn, 'SELECT 1 AS a, 2 AS a, 3 AS \"a..2\"')\n\n##   a a..2 a..3\n## 1 1    2    3"
  },
  {
    "objectID": "blog/dbi-2-final/index.html#helpers",
    "href": "blog/dbi-2-final/index.html#helpers",
    "title": "Done “Establishing DBI”!?",
    "section": "Helpers",
    "text": "Helpers\nTwo little helper generics have been added.\nThe new dbIsReadOnly() generic (contributed by Anh Le) should return TRUE for a read-only connection. This is not part of the specification yet.\nThe dbCanConnect() tests a set of connection parameters. The default implementation simply connects and then disconnects upon success. For DBMS that can provide more efficient methods of checking connectivity, a lighter-weight implementation of this method may give a better experience.\nNone of the three backends currently provide specialized implementations for these generics."
  },
  {
    "objectID": "blog/dbi-2-final/index.html#code-reuse",
    "href": "blog/dbi-2-final/index.html#code-reuse",
    "title": "Done “Establishing DBI”!?",
    "section": "Code reuse",
    "text": "Code reuse\nI have made some efforts to extract common C++ classes for assembling data frames and prepare them for reuse. The C++ source code for the three backends contains files prefixed with Db, these are almost identical across the backends. The planned packaging into the RKazam package had to yield to higher-priority features described above.\nThe situation in the R code is similar: I have found myself copy-pasting code from one backend into another because I didn’t feel it’s ready (or standardized enough) to be included in the DBI package.\nFor both use cases, a code reuse strategy based on copying/updating template files or reconciling files may be more robust than the traditional importing mechanisms offered by R."
  },
  {
    "objectID": "blog/dbi-2-final/index.html#outlook",
    "href": "blog/dbi-2-final/index.html#outlook",
    "title": "Done “Establishing DBI”!?",
    "section": "Outlook",
    "text": "Outlook\nThe upcoming CRAN release of DBI, DBItest and the three backends RSQLite, RMariaDB and RPostgres are an important milestone. Stability is important when more and more users and projects use the new backends. Nevertheless, I see quite a few potential improvements that so far were out of scope of the “Improving DBI” and “Establishing DBI” projects:\n\nSupport running the test suite locally, to validate adherence to DBI for a particular installation.\nConsistent fast data import.\nConsistent query placeholders (currently $1 for RPostgres and ? for many other backends).\nSupport for arbitrary data types via hooks.\nAssistance with installation problems on specific architectures, or connectivity problems with certain databases, or other specific issues.\nRework the internal architecture of DBItest to simplify locating test failures.\nImprove the https://r-dbi.org website.\nNon-blocking queries.\n\nI have submitted another proposal to the R Consortium, hoping to receive support with these and other issues."
  },
  {
    "objectID": "blog/dbi-2-final/index.html#acknowledgments",
    "href": "blog/dbi-2-final/index.html#acknowledgments",
    "title": "Done “Establishing DBI”!?",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI’d like to thank the R Consortium for their generous financial support. Many thanks to the numerous contributors who helped make the past two projects a success."
  },
  {
    "objectID": "blog/dbi-4-2/index.html",
    "href": "blog/dbi-4-2/index.html",
    "title": "Towards sustainable DBI maintenance",
    "section": "",
    "text": "For 2022 and 2023, no concrete new features were planned. Instead, the focus has been on establishing a sustainable and steady pace of maintenance and responsiveness to user feedback. This blog post shows how we have been doing in this regard.\nThis is a continuation of the first blog post in this series.\nThis analysis is based on the GitHub issues opened in the r-dbi organization since development has moved to GitHub, for the following packages: DBI, DBItest, RMariaDB, RPostgres, RSQLite, dblog, RKazam. See https://github.com/r-dbi/issues/ for the source of the analysis.\nIn total, 2086 issues and pull requests were opened in the package repositories, of which 462 were opened in 2022 or later.\nThe bar chart shows the number of issues opened per year. In recent years, the vast majority of the issues were opened by contributors and non-members.\nTo analyze responsiveness, we consider the time it takes from opening an issue by a non-member to the first response by a member, and to closing the issue.\nResponsiveness to issues has improved, the majority of issues are now responded to within a single day. Unfortunately, some issues still required more than two weeks until the first response. The situation is similar for pull requests: Some are reviewed within a few days, but others remain unreviewed for more than two weeks.\nThe time to close issues varies too. Many can be closed within a day or a week, but some issues remain open for months or even years. For PRs, it depends whether they were created by CI/CD or by a human. Autogenerated PRs tend to get merged or closed much faster, but the general pattern is similar to issues."
  },
  {
    "objectID": "blog/dbi-4-2/index.html#moving-forward",
    "href": "blog/dbi-4-2/index.html#moving-forward",
    "title": "Towards sustainable DBI maintenance",
    "section": "Moving forward",
    "text": "Moving forward\nUnfortunately, I’m using RPostgres, RMariaDB and RSQLite only in a lab setting, not in production. The new docker repository is a step towards making it easier to test various combinations of database servers and client libraries. I hope that this will make it easier to experience what using these tools in production is like, perhaps in combination with increasing network latency and throttling bandwidth.\nNo lab setup can replace the experience of using these tools in production. To effectively maintain DBI and the backend packages, I rely on contributed issues and pull requests. I’m grateful for every issue opened, even if some may be not actionable for me. Luckily, for a substantial number of the issues, the first response actally comes from a contributor! If you are interested in helping out, consider watching one or several repositories in the r-dbi organization.\nThanks to Maëlle Salmon (@maelle) and Nicolas Bennett (@nbenn) for their help with the blog post."
  },
  {
    "objectID": "blog/dbi-3-3/index.html",
    "href": "blog/dbi-3-3/index.html",
    "title": "Maintaining DBI, 3/4",
    "section": "",
    "text": "DBI stands for database interface. The DBI package connects R to database management systems (DBMS). The goal of DBI is to provide a common interface for database access, regardless of the specific underlying DBMS. DBI works with a variety of DBMS, such as Postgres, MariaDB, and SQLite, through dedicated backend packages. For first-time users I recommend starting with the new introductory tutorial.\nThe current version of DBI is 1.1.1. This blog post attempts to define the scope of the DBI project, summarizes recent developments in DBI and related packages, and showcases future work."
  },
  {
    "objectID": "blog/dbi-3-3/index.html#what-is-dbi",
    "href": "blog/dbi-3-3/index.html#what-is-dbi",
    "title": "Maintaining DBI, 3/4",
    "section": "",
    "text": "DBI stands for database interface. The DBI package connects R to database management systems (DBMS). The goal of DBI is to provide a common interface for database access, regardless of the specific underlying DBMS. DBI works with a variety of DBMS, such as Postgres, MariaDB, and SQLite, through dedicated backend packages. For first-time users I recommend starting with the new introductory tutorial.\nThe current version of DBI is 1.1.1. This blog post attempts to define the scope of the DBI project, summarizes recent developments in DBI and related packages, and showcases future work."
  },
  {
    "objectID": "blog/dbi-3-3/index.html#scope-of-the-dbi-project",
    "href": "blog/dbi-3-3/index.html#scope-of-the-dbi-project",
    "title": "Maintaining DBI, 3/4",
    "section": "Scope of the DBI project",
    "text": "Scope of the DBI project\nThe DBI package is perfect for anyone looking to connect to a database, read/write entire tables, and/or execute SQL queries. DBI gives a direct access to the database driver, leaving more sophisticated data query and manipulation tasks to packages like dbplyr, dbx and rquery.\nThe core DBI project in R provides an interface for databases, specified in textual form and via automated tests. The DBI specification contains a detailed description of the methods provided by DBI. In summary, the interface covers:\n\nDiscovery of tables, also in schemas\nReading/writing/creating/removing tables\nExecuting queries, fetching data (with parameters)\nSafe quoting: low-level composition of queries\nTransactions\n\nDBI should provide a way to ingest data of any type into R, at least in serialized form (e.g. string or blob). It should offer a robust reliable interface for dependent packages; anything beyond this scope should be left to packages that extend DBI:\n\narkdb: archival of database data\nconnection: integrate database connections with the RStudio IDE\ndbplyr and rquery: generation of SQL queries\ndbx: DBI extension for data manipulation\ndittodb: mocking for databases\ndm: relational data models (via dbplyr)\npool: connection pooling\nsqlr: schema definition\n\nand many more."
  },
  {
    "objectID": "blog/dbi-3-3/index.html#recent-developments-in-dbi",
    "href": "blog/dbi-3-3/index.html#recent-developments-in-dbi",
    "title": "Maintaining DBI, 3/4",
    "section": "Recent developments in DBI",
    "text": "Recent developments in DBI\nThis section discusses:\n\nthe new DBI tutorials,\nimprovements for datetime data,\nother notable changes,\nthe move to GitHub Actions.\n\nThe first three items directly affect DBI users, the last item much less so. It is nevertheless an important investment in the stability of the DBI infrastructure.\n\nNew tutorials\nJames Wondrasek substantially expanded the “Introduction to DBI” article and added a second article. DBI now features two tutorials. The introduction includes a walkthrough that describes connecting and querying a real database. The “Advanced DBI usage” tutorial shows more advanced examples of quoting and parameter binding. The tutorials are an important first-hand resource for new users.\n\n\nTime zones\nTo date, it was only possible to work reliably with time zones when the database connection represented all times in UTC. This poses a few problems in practice:\n\nNot all databases store timestamps as UTC or with time zone offset, often local time is assumed by the data model.\nOther systems often use the default setting for time zone, this harms interoperability of DBI in these cases.\nConversion of timestamps to dates via the SQL function DATE is only correct when the session time zone is set correctly.\n\nRMariaDB 1.1.0 and RPostgres 1.3.0 gained more robust support for datetime values. As proposed in the previous blog post, new arguments timezone and timezone_out were added. Both arguments should use Olson names such as Europe/Berlin or America/New_York, not time offsets like +01:00; the latter may change with daylight time savings season. If timezone is set to NULL, an attempt is made to detect the correct time zone on the database. Thanks to Philipp Schauberger for contributing the initial timezone argument for RMariaDB.\nRSQLite does not natively support dates or times. A promising pull request is underway that implements support for treating numeric values as time offsets if the column type is declared in a specific way.\n\n\nNotable changes to DBI backends\nThe following package versions were sent to CRAN since the last blog post:\n\nDBI 1.1.0 -&gt; 1.1.1 (NEWS)\nRMariaDB 1.0.8 -&gt; 1.1.0 (NEWS)\nRPostgres 1.2.0 -&gt; 1.3.1 (NEWS)\nRSQLite 2.1.5 -&gt; 2.2.2 (NEWS)\n\nHighlights are:\n\nDBI: Two new tutorials; minor improvements to dbQuoteLiteral(), this is relevant for backends that don’t provide their own implementation.\nRMariaDB: Better handling of data types and character encoding; minor tweaks to dbBind() and dbQuoteLiteral().\nRPostgres: The new Redshift() driver that allows downstream packages to distinguish between Postgres and Amazon RedShift (thanks Hadley Wickham); minor improvements for querying and passing date and time types, postgresWaitForNotify() contributed by Jamie Lentin.\nRSQLite: dbAppendTable() is faster, strings and blobs can have virtually unlimited size (limit 2 GB), embedded SQLite library is now in version 3.34.\nDBItest: understanding which tests failed is now simpler, also thanks to simpler backtraces; test_some() integrates with the dblog package and shows DBI methods called; established compatibility with testthat 3.0.0; better and more robust tests.\nRKazam: Is now a template repository\n\nThanks to Jeroen Ooms for maintaining Windows versions for the database libraries.\n\n\nQA and automation\nAutomated tests are a crucial part of modern software engineering. These are often augmented with continuous integration (CI) services that run these tests regularly or with every change to the code. When I started working on DBI, Travis CI offered excellent continuous integration services for open-source repositories. Unfortunately, this is no longer the case: the free tier introduced a limit on CI build time, rendering it effectively unusable for DBI.\nGitHub Actions is a CI/CD platform tightly integrated with GitHub. It is somewhat simpler to set up, also for creating workflows that e.g. open a pull request. It is sufficient to add a YAML configuration file to a dedicated location in the repository. Each build automatically obtains a token that can be used to interact with the GitHub API. R support is provided by dedicated workflows and actions contributed by RStudio. Check status is conveniently reported in detail with each pull request, and the checks run considerably faster due to higher concurrency.\nContinuous integration for all packages in the project has moved to GitHub Actions. Cross-platform checks for all backends on the major operating systems were a bit challenging, because the tests require a live database. Thanks to Andrew Kane for providing GitHub actions that install database engines on all platforms, this greatly simplified the move.\nThree more parts of the infrastructure were updated as part of the move:\n\nThe odbc and duckdb packages are now also checked when the DBItest package updates. This ensures that new or amended specifications do not break these packages. If you maintain a DBI backend that uses DBItest, get in touch for integrating your backend with these checks.\nThe list of DBI backends is now continuously updated. Updates to backends are applied automatically. Every time a new backend is found, a pull request is opened.\nA new pull request is opened in RSQLite when a new version of the SQLite library is available. This makes it much easier to keep the bundled SQLite version up to date."
  },
  {
    "objectID": "blog/dbi-3-3/index.html#future-work",
    "href": "blog/dbi-3-3/index.html#future-work",
    "title": "Maintaining DBI, 3/4",
    "section": "Future work",
    "text": "Future work\nThe last blog post already identified major milestones:\n\nquery cancellation\ntesting on remote databases\n\nA triage of the contributed issues has identified the following additional major topics:\n\nimmediate argument to dbSendQuery() and dbSendStatement() for RMariaDB and RPostgres\nperformance of table import\nreconnect if a database connection is lost\n\nOther minor issues include:\n\nSSL connections\nauthentication plugins\nsupport for more data types: arrays, JSON, …\n\nI’m planning to resolve most of the remaining issues in a final sprint. Some of these issues can be outsourced to other packages, according to the scope outlined in the previous sections, priority should be given to issues that must be resolved in the core packages. Future work might shift towards providing or improving useful extensions."
  },
  {
    "objectID": "blog/dbi-3-3/index.html#acknowledgments",
    "href": "blog/dbi-3-3/index.html#acknowledgments",
    "title": "Maintaining DBI, 3/4",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nI’d like to thank James Wondrasek for creating the DBI tutorials and for a review of this blog post, Angelica Becerra for reviewing the material, and the numerous contributors to the packages in the “Maintaining DBI” project (DBI¹, RSQLite², RPostgres³, RMariaDB⁴, and DBItest⁵):\n@abalter³, @alanpaulkwan², @AllenSuttonValocity³, @altay-oz³, @anderic1², @andybeet¹, @arencambre⁴, @artemklevtsov³, @bastianilso⁴, @bczernecki¹, @Byggvir⁴, @Chrisjb¹, @clementbfeyt⁴, @colearendt¹, @daattali¹, @datawookie¹, @dpprdan³⁵, @elfatherbrown⁴, @EntwicklR², @ericemc3⁴, @formix³, @fproske¹, @georgevbsantiago¹, @GitHunter0¹, @hadley²³, @hmeleiro¹, @hpages², @imlijunda³, @inferiorhumanorgans³, @jarauh⁴, @jawond¹, @jeroen³, @jimhester¹, @jjesusfilho³, @jsilve24², @kforner⁴, @kmishra9², @Kodiologist¹², @LaugeGregers³, @luispuerto², @martinstuder⁵, @matteodelucchi⁴, @MaximumV¹, @mbannert³, @mbedward³, @mgirlich², @mlamias¹, @mllg¹, @mmuurr³, @momeara³, @MonteShaffer⁴, @Mosk915⁴, @nfultz², @norquanttech³, @OMalytics³, @oriolcmp⁴, @Osc2wall⁴, @psychobas², @randyzwitch⁵, @rcfree², @rnorberg¹, @rodriguesk², @rossholmberg⁴, @Sahil308⁴, @samuel-cs4⁴, @schuemie², @shutinet², @splaisan², @Trowic⁴, @verajosemanuel⁴, @VictorYammouni¹, @vigyoyo⁴, @vikram-rawat³, @vspinu³, @warnes³, @wiligl², @ycphs⁴, and @zyxdef¹."
  },
  {
    "objectID": "blog/dbi-1-halfway/index.html",
    "href": "blog/dbi-1-halfway/index.html",
    "title": "Halfway through “Improving DBI”",
    "section": "",
    "text": "In early 2016 the R Consortium partially accepted my “Improving DBI” proposal. An important part is the design and implementation of a testable DBI specification. Initially I also proposed to make three DBI backends to open-source databases engines (RSQLite, RMySQL, and RPostgres) compatible to the new DBI specification, but funding allows to work on only one DBI backend. I chose RSQLite for a number of reasons:\nThe project has reached an important milestone, with the release of RSQLite 1.1. This post reports the progress achieved so far, and outlines the next steps."
  },
  {
    "objectID": "blog/dbi-1-halfway/index.html#rsqlite",
    "href": "blog/dbi-1-halfway/index.html#rsqlite",
    "title": "Halfway through “Improving DBI”",
    "section": "RSQLite",
    "text": "RSQLite\nWhile the RSQLite API has changed very little (hence the minor version update), it includes a complete rewrite of the original 1.0.0 sources in C++. This has considerably simplified the code, which makes future maintenance easier, and allows us to take advantage of the more sophisticated memory management tools available in Rcpp, which help protect against memory leaks and crashes.\nRSQLite 1.1 brings a number of improvements:\n\nNew strategy for prepared queries: Create a prepared query with dbSendQuery() or dbSendStatement() and bind values with dbBind(). This allows you to efficiently re-execute the same query/statement with different parameter values iteratively (by calling dbBind() several times) or in a batch (by calling dbBind() once with a data-frame-like object).\nSupport for inline parametrised queries via the param argument to dbSendQuery(), dbGetQuery(), dbSendStatement() and dbExecute(), to protect from SQL injection.\nThe existing methods dbSendPreparedQuery() and dbGetPreparedQuery() have been soft-deprecated, because the new API is more versatile, more consistent and stricter about parameter validation.\nUsing UTF8 for queries and parameters: this mean that non-English data should just work without any additional intervention.\nImproved mapping between SQLite’s cell-types and R’s column-types.\n\nSee the release notes for further changes.\nThe rewrite was implemented by Hadley Wickham before the “Improving DBI” project started, and has been available for a long time on GitHub. Nevertheless, the CRAN release has proven much more challenging than anticipated, because so many CRAN and Bioconductor packages import it. (Maintainers of reverse dependencies might remember multiple e-mails where I was threatening to release RSQLite “for real”.) My aim was to break as little existing code as possible. After numerous rounds of revdep-checking and improving RSQLite, I’m proud to report that the vast majority of reverse dependencies pass their checks just as well (and as quickly!) as they did with v1.0.0. Most tests from v1.0.0 are still present in the current codebase. This means that non-packaged code also has a good chance to work unchanged. I’m happy to work with package maintainers or users whose code breaks after the update.\nDBI\n\nI have also released several DBI updates to CRAN, mostly to introduce new generics such as dbBind() (for parametrized/prepared queries) or dbSendStatement() and dbExecute() (for statements which don’t return data). The definition of a formal DBI specification is part of the project, a formatted version is updated continuously."
  },
  {
    "objectID": "blog/dbi-1-halfway/index.html#dbitest",
    "href": "blog/dbi-1-halfway/index.html#dbitest",
    "title": "Halfway through “Improving DBI”",
    "section": "DBItest",
    "text": "DBItest\nIn addition to the textual specification in the DBI package, the DBItest package provides backend independent tests for DBI packages. It can be easily used by package authors to ensure that they follow the DBI specification. This is important because it allows you to take code that works with one DBI backend and easily switch to a different backend (providing that they both support the same SQL dialect). Literate programming techniques using advanced features of roxygen2 help keeping both code and textual specifications in close proximity, so that amendments to the text can be easily tracked back to changes of the test code, and vice versa."
  },
  {
    "objectID": "blog/dbi-1-halfway/index.html#next-steps",
    "href": "blog/dbi-1-halfway/index.html#next-steps",
    "title": "Halfway through “Improving DBI”",
    "section": "Next steps",
    "text": "Next steps\nThe rest of the project will focus on finalizing the specification in both code and text (mostly discussed on GitHub in the issue trackers for the DBI and DBItest projects). At least one new helper package (to handle 64-bit integer types) will be created, and DBI, DBItest, and RSQLite will see yet another release: The first two will finalize the DBI specification, and RSQLite will fully conform to it.\nThe development happens entirely on GitHub in repositories of the r-dbi organization. Feel free to try out development versions of the packages found there, and to report any problems or ideas at the issue trackers."
  },
  {
    "objectID": "blog/dbi-3-1/index.html",
    "href": "blog/dbi-3-1/index.html",
    "title": "Maintaining DBI, 1/4",
    "section": "",
    "text": "Much earlier this year my proposal for the third R Consortium project for working on DBI has been accepted. DBI is a set of virtual functions declared in the DBI package. Communication with the database is implemented by DBI backends, packages that import DBI and implement its methods. A common interface is helpful for both users and backend implementers. Users, including package developers for DBMS-agnostic packages, need to memoize only one set of functions. Backend developers can focus on functionality instead of design decisions, and can benefit from a large base of potential users right from the start.\nI’m grateful for the trust, and will do my best to make the “Maintaining DBI” project a success. For this round, the main goals are: maintain, enhance, disseminate. The project is delayed mostly becase I grossly underestimated how much time and energy it would take to set up cynkra. The new joint venture with Christoph Sax consults businesses and organizations on matters related to R, statistics, data, and software. We are strongly committed to R and open-source software, and more priority will be given the “Maintaining DBI” project next year.\nThis blog post, much later than planned, summarizes the efforts of the past year: presentations at meetups, the “Core Infrastructure Initiative” badge, and activity in the various repositories of the r-dbi GitHub organization. I’ll repeat the big picture issues from the proposal and present plans for future development."
  },
  {
    "objectID": "blog/dbi-3-1/index.html#presentations-at-meetups",
    "href": "blog/dbi-3-1/index.html#presentations-at-meetups",
    "title": "Maintaining DBI, 1/4",
    "section": "Presentations at meetups",
    "text": "Presentations at meetups\nI presented DBI at the Berlin R user group, at the amstRdays, and at the Zurich R meetup. The presentation in Berlin made me realize that a progress report isn’t that helpful for a general audience. The Zurich version of the presentation featured a DBI intro also suitable for new users, merely highlighting recent developments. These slides, and the intro at db.rstudio.com seem to be the most recent general-purpose introduction materials available. I think an entry-level tutorial would be a good fit for a DBI vignette."
  },
  {
    "objectID": "blog/dbi-3-1/index.html#cii-badge",
    "href": "blog/dbi-3-1/index.html#cii-badge",
    "title": "Maintaining DBI, 1/4",
    "section": "CII badge",
    "text": "CII badge\nFrom https://bestpractices.coreinfrastructure.org/en:\n\nThe Linux Foundation (LF) Core Infrastructure Initiative (CII) Best Practices badge is a way for Free/Libre and Open Source Software (FLOSS) projects to show that they follow best practices. Projects can voluntarily self-certify, at no cost, by using this web application to explain how they follow each best practice. The CII Best Practices Badge is inspired by the many badges available to projects on GitHub. Consumers of the badge can quickly assess which FLOSS projects are following best practices and as a result are more likely to produce higher-quality secure software.\n\nThe CII badge can be obtained after a self-certification process that comprises ~70 soft and hard questions about the project around the following topics:\n\nBasics: Project URLs, license, documentation\nChange Control: Version control and version numbers\nReporting: Tracking issues and vulnerabilities\nQuality: Build and test system, best practices\nSecurity (software)\nAnalysis (static and dynamic)\n\nAfter completing the process, projects are entitled to wear a badge like the one below for the DBI project:\n\n\n\nOpenSSF Best Practices\n\n\nA click on the badge takes you to the detailed assessment. In addition to the badge, completing the self-certification allows the maintainer to rethink if workflows and practices can be improved.\nDBI is currently has the “passing” status, the backend packages and DBItest will follow. I have compiled the changes that were necessary to obtain that status below. It appears to be much more difficult but not impossible to obtain the “silver” status.\n\nNecessary changes to the DBI package\nSeveral files had to be added or updated:\n\nCONTRIBUTING.md: This file describes how to contribute to the project. A link to this file is available when you open a new issue. The function usethis::use_tidy_contributing() created the files which I tweaked a bit.\nLICENSE.md: The full license terms need to be available as part of the project. To create the file, I contributed usethis::use_lgpl_2.1_license(). Because CRAN discourages redistribution of copies of standard license texts in packages, the file has been added to .Rbuildignore. This makes the file available in the GitHub repository, but not package file on CRAN.\nREADME.md: Added missing installation instructions.\n\nThough not on the CII badge checklist, I also added:\n\nISSUE_TEMPLATE.md: pre-populates the issue description when opening a new issue. This is a tweaked version of the file provided by usethis::use_tidy_issue_template().\nCODE_OF_CONDUCT.md: The default file as added by usethis::use_code_of_conduct().\n\nOne badge still had an HTTP image source, after changing it to HTTPS the criterion that the website needs to use TLS was satisfied.\nEstablishing a process for reporting code vulnerabilities was perhaps the most challenging part. It seems unclear if it applies to R packages at all, in particular to an interface-only package such as DBI. The solution was to add a link with text to the project page https://dbi.r-dbi.org, asking to send an e-mail and await further instructions."
  },
  {
    "objectID": "blog/dbi-3-1/index.html#future-development",
    "href": "blog/dbi-3-1/index.html#future-development",
    "title": "Maintaining DBI, 1/4",
    "section": "Future development",
    "text": "Future development\nThe principal roadmap for future development has been outlined in the project proposal. There are both “hard” and “soft” issues to solve, repeated below, with comments based on experience from the past year.\n\n“Hard” issues\n\nThe test suite for the DBI specificaton in DBItest is currently designed to run as part of the package checks. The next step is to support running the test suite against a particular R + DBMS installation, to ensure that code interoperating with that DBMS in that environment runs as expected.\n\nShouldn’t be too hard, but need to keep the second “soft” issue in mind.\n\nUsers expect the hard disk or the DBMS to be the limiting factor for loading data, but DBI still lacks a consistent interface for fast data import.\n\nThe new arkdb package offers a dedicated interface for importing data, I still think this functionality should better live there (or elsewhere).\n\nThe syntax for query placeholders currently depends on the DBMS. A consistent interface would be useful, in particular for implementers of packages that compute on the database.\n\nThis has already caused some confusion. Shouldn’t be too hard either, but requires a compatibility mode so that existing code doesn’t break.\n\nThe RPostgres package now has special handling for geometry data. A generic extension to arbitrary data types via hooks would allow e.g. returning JSON data directly as a \"json\" class without user-initiated manual conversion.\n\nThis seems to be a bigger problem, requiring some thought and design.\n\n\n\n\n“Soft” issues\n\nSome users reported installation problems on specific architectures, or connectivity problems with certain databases, or other specific issues. Making the new backends accessible for various combinations of OS/hardware, software, and configuration, will help the adoption of the new packages.\n\nI remember seeing many SSL and timezone issues, as well as genuine bugs like the representation of times before 1970 on Windows. Expect some progress for the second blog post.\n\nThe internal architecture of the DBI specification in DBItest requires a bit of reworking. Currently, it is difficult to understand a test failure without inspecting the source code of DBItest. It is difficult to locate the source of a failure in the specification and in the code. Ideally, each test failure would come with a precise link to the part of the specification that is violated, and with a simple sequence of DBI method calls that allow replicating the failure externally.\n\nThat code I wrote 1-2 years ago requires some attention…\n\nThe communication related to the projects has been rather terse so far. The new website https://r-dbi.org can host blog posts highlighting different aspects of DBI, and serve as a resource for advice on connecting R with databases and computing on the database. This includes coordination and support for developments around DBI like sqlr, an interface for data definition statements on top of DBI.\n\nTogether with the new Databases CRAN Task View maintained by Yuan (Terry) Tang and https://solutions.posit.co/connections/db/, the https://r-dbi.org should become a viable resource for new and experienced users alike. New users should be directed to tutorials and introductory material, whereas experienced users should expect to find pointers to solve the most common problems. The role of each of these websites remains to be shaped, some overlap may be desired.\n\nAll operations on DBI currently block until a result is available or the DBMS has indicated completion. Asynchronous operations allow parallel processing of multiple queries or statements, however some research is necessary to understand to what extent this can be supported realistically in DBI and for the existing backends.\n\nAdditional arguments to dbConnect(), like the new check_interrupts argument contributed to RPostgres by Mateusz Żółtak, are an option to experiment with asynchronous processing without disrupting existing code.\n\n\nThese lists are not comprehensive, new issues may surface over time, or the importance of issues mentioned above may fade."
  },
  {
    "objectID": "blog/dbi-3-1/index.html#outlook-next-blog-post",
    "href": "blog/dbi-3-1/index.html#outlook-next-blog-post",
    "title": "Maintaining DBI, 1/4",
    "section": "Outlook: next blog post",
    "text": "Outlook: next blog post\nThe “Maintaining DBI” project is driven by blog posts. I promised four blog posts, describing the ongoing maintenance and development.\nFor the next iteration, I plan to improve documentation, do a release round for all packages, furnish more packages with a CII badge, review several new packages that build on top of DBI, and improve my responsiveness.\nA Walkthrough for first-time DBI users seems to be the highest priority, perhaps accompanied by an online course. Other documentation improvements mostly will address https://r-dbi.org.\nThe following is an excerpt of changes in the forthcoming CRAN releases of the DBI packages:\n\nRSQLite: window functions!\nRMariaDB: better handling for time zones\nDBItest: minor improvements\n\nNew packages worth reviewing include:\n\narkdb: Consistent (and fast?) import and export\nflobr: Converting files to blobs and back\nsqlr: SQLAlchemy-like DSL for data definition, work in progress\ndbplot: Plotting from the database\nand many others.\n\nAdding CII badges for the backend packages and DBItest will give a more consistent appearance of the entire project.\nAs a New Year’s resolution, I pledge to do a better job as package maintainer for DBI and related packages. I reserved a few hours each Monday to respond to issues raised on GitHub and other channels (SO, RStudio Community, Twitter, and the somewhat underappreciated R-SIG-DB mailing list). CI builds on Travis and AppVeyor also require occasional intervention. The remaining time will be spent on resolving known problems."
  },
  {
    "objectID": "blog/dbi-3-1/index.html#acknowledgments",
    "href": "blog/dbi-3-1/index.html#acknowledgments",
    "title": "Maintaining DBI, 1/4",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nThanks to all contributors to DBI and the other projects in the r-dbi organization!\n\n\n\nDBI contributors"
  }
]